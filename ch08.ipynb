{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "view-in-github",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/ch08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Dzthx6REAOrZ",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Rendering sympy equations requires MathJax to be available within each cell output. \n",
    "# The following is a function that will make this happen for Colab.\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    \n",
    "    from sympy import init_printing\n",
    "    from sympy.printing import latex\n",
    "\n",
    "    def colab_LaTeX_printer(exp, **options):  \n",
    "        from google.colab.output._publish import javascript \n",
    "\n",
    "        url_ = \"https://colab.research.google.com/static/mathjax/MathJax.js?\"\n",
    "        cfg_ = \"config=TeX-MML-AM_HTMLorMML\" # \"config=default\"\n",
    "\n",
    "        javascript(url=url_+cfg_)\n",
    "\n",
    "        return latex(exp, **options)\n",
    "\n",
    "    init_printing(use_latex=\"mathjax\", latex_printer=colab_LaTeX_printer)\n",
    "else:\n",
    "    import sympy\n",
    "    sympy.init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qS9vSfZ3AOrh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 8. Matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "colab_type": "text",
    "id": "24ZPMz8YAOri",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Contents\n",
    "\n",
    "* Matrix Algebra\n",
    "* Systems of Linear Algebraic Equations\n",
    "* Rank of Matrix\n",
    "* Determinants\n",
    "* Properties of Determinants\n",
    "* Inverse of Matrix\n",
    "* Cramer's Rule\n",
    "* The Eigenvalue Problem        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$~$\n",
    "\n",
    "* Powers of Matrices\n",
    "* Orthogonal Matrices\n",
    "* Approximation of Eigenvalues\n",
    "* Diagonalization\n",
    "* LU-factorization\n",
    "* Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4272BrhAOrj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.1 $~$ Matrix Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A **matrix** is any rectangular array of numbers or functions\n",
    "\n",
    " >$\\begin{pmatrix}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n}\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} \\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots \\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "  \\end{pmatrix}$  \n",
    "   \n",
    "  * The numbers or functions in the array are **entries** or **elements**\n",
    "  * An $n \\times n$ matrix  is a **square** matrix of **order $n$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "colab_type": "text",
    "id": "cXFIY453AOrl",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Column** and **row vectors** are $n \\times 1$ and $1 \\times n$ matrices\n",
    "\n",
    "  >$\n",
    "  \\begin{pmatrix}\n",
    "    a_1\\\\ \n",
    "    a_2\\\\ \n",
    "    \\vdots\\\\ \n",
    "    a_n\n",
    "  \\end{pmatrix},\\;\n",
    "  \\begin{pmatrix}\n",
    "    a_1 & a_2 & \\cdots & a_n\n",
    "  \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Equality of Matrices** \n",
    "\n",
    "  $\\mathbf{A} = \\left(a_{ij}\\right)_{m \\times n}\\text{ }$ and $\\text{ }\\mathbf{B} = \\left(b_{ij}\\right)_{m \\times n}\\text{ }$ are *equal* $~$if $a_{ij}=b_{ij}$ for each $i$ and $j$\n",
    "  \n",
    "* **Matrix Addition**\n",
    "\n",
    "  $\\mathbf{A} +\\mathbf{B} = \\left(a_{ij} +b_{ij}\\right)_{m \\times n}$\n",
    "  \n",
    "* **Scalar Multiplication**\n",
    "\n",
    "  $k\\mathbf{A} = \\left(ka_{ij}\\right)_{m \\times n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crV4LYHWAOrn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Properties of Matrix Addition and Scalar Multiplication**\n",
    "\n",
    "  Suppose $\\mathbf{A}$, $\\mathbf{B}$, and $\\mathbf{C}$ are $m \\times n$ matrices and $k_1$ and $k_2$ are scalars. Then\n",
    "\n",
    "  >$\\begin{align*}\n",
    "    &\\mathbf{A} +\\mathbf{B} = \\mathbf{B} +\\mathbf{A} \\\\ \n",
    "    &\\mathbf{A} +\\left(\\mathbf{B} +\\mathbf{C}\\right) = \\left(\\mathbf{A} +\\mathbf{B}\\right) +\\mathbf{C} \\\\\n",
    "    &\\left(k_1 k_2\\right)\\mathbf{A} = k_1 \\left(k_2\\mathbf{A}\\right) \\\\\n",
    "    &k_1\\left(\\mathbf{A} +\\mathbf{B}\\right)=k_1\\mathbf{A} +k_1\\mathbf{B} \\\\\n",
    "    &\\left(k_1 +k_2\\right)\\mathbf{A} = k_1 \\mathbf{A} +k_2\\mathbf{A}  \n",
    "  \\end{align*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbkQpqGnAOrp",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Matrix multiplication** \n",
    "  \n",
    "  >$\\displaystyle\\mathbf{A}\\mathbf{B}=\\left(\\sum_{k=1}^p a_{ik} b_{kj}\\right)_{m \\times n}$\n",
    "  \n",
    "  where $\\mathbf{A}$ is an $m \\times p$ matrix, $~\\mathbf{B}$ is a $p \\times n$ matrix, and\n",
    "  $~\\mathbf{A}\\mathbf{B}$ is the $m \\times n$ matrix\n",
    "  \n",
    "  * In general, $~\\mathbf{A}\\mathbf{B}\\neq\\mathbf{B}\\mathbf{A}$\n",
    "  \n",
    "  * **Associative Law:** $~\\mathbf{A}\\left(\\mathbf{B}\\mathbf{C}\\right)=\\left(\\mathbf{A}\\mathbf{B}\\right)\\mathbf{C}$ \n",
    "  \n",
    "  * **Distributive Law:** $~\\mathbf{A}\\left(\\mathbf{B}+\\mathbf{C}\\right)=\\mathbf{A}\\mathbf{B} +\\mathbf{A}\\mathbf{C}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvEQm1zSAOrt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Transpose of a Matrix**\n",
    "\n",
    "  >$\\mathbf{A}^T =\n",
    "  \\begin{pmatrix}\n",
    "    a_{11} & a_{21} & \\cdots & a_{m1}\\\\ \n",
    "    a_{12} & a_{22} & \\ddots & a_{m2} \\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots \\\\ \n",
    "    a_{1n} & a_{2n} & \\cdots & a_{mn}\n",
    "  \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "* **Properties of Transpose**\n",
    "\n",
    "  >$\n",
    "  \\begin{align*}\n",
    "     &\\left(\\mathbf{A}^T\\right)^T=\\mathbf{A} \\\\ \n",
    "     &\\left(\\mathbf{A} +\\mathbf{B}\\right)^T=\\mathbf{A}^T +\\mathbf{B}^T \\\\ \n",
    "     &\\left(\\mathbf{A}\\mathbf{B}\\right)^T=\\mathbf{B}^T\\mathbf{A}^T \\\\ \n",
    "     &\\left(k\\mathbf{A}\\right)^T=k\\mathbf{A}^T\n",
    "   \\end{align*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2qnoQaiAOrw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Special Matrices**\n",
    "\n",
    "  * In a **zero matrix**, $~$all entries are zeros\n",
    "  \n",
    "  * In a **triangular matrix**, $~$all entries above or below the main diagonal are zeros (lower triangular or upper triangular)\n",
    "  \n",
    "  * In a **diagonal matrix**, $~$all entries not on the main diagonal are zeros\n",
    "  \n",
    "  * A **scalar matrix** is a diagonal one where all entries on the main diagonal are equal.\n",
    "    $~$If those entries are $1$'s, it is an **identity matrix**, $\\mathbf{I}$ \n",
    "    (or $\\mathbf{I}_n$ when there is a need to emphasize the order of the matrix)\n",
    "    \n",
    "  * An $n \\times n$ matrix $\\mathbf{A}$ is **symmetric** $~$if $\\mathbf{A}^T=\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbKN9ESLAOrx",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.1\n",
    "\n",
    "* If $\\mathbf{A}=\\begin{pmatrix}\n",
    " \\phantom{-}2 & -3 \\\\ \n",
    " -5 & \\phantom{-}4 \n",
    "\\end{pmatrix}$ and $\\mathbf{B}=\\begin{pmatrix}\n",
    " -1 & 6 \\\\ \n",
    " \\phantom{-}3 & 2 \n",
    "\\end{pmatrix}$, $~$find $~$(a) $\\mathbf{AB}$, $~$(b) $\\mathbf{BA}$, $~$(c) $\\mathbf{A}^2$, $~$(d) $\\mathbf{B}^2$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Show that if $\\mathbf{A}$ is an $m\\times n$ matrix, $~$then $\\mathbf{AA}^T$ is symmetric\n",
    "\n",
    "  $~$\n",
    "\n",
    "* In matrix theory, $~$many of the familiar properties of the real number system are not valid. $~$If $a$ and $b$ are real numbers, then $ab=0$ implies that $a=0$ or $b=0$. $~$Find two matrices such that $\\mathbf{AB}=\\mathbf{0}$ but $\\mathbf{A}\\neq\\mathbf{0}$ and $\\mathbf{B}\\neq \\mathbf{0}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let $\\mathbf{A}$ and $\\mathbf{B}$ be $n\\times n$ matrices. Explain why, in general, the given formula is not valid\n",
    "\n",
    "  $(\\mathbf{A} + \\mathbf{B})^2 = \\mathbf{A}^2 + 2\\mathbf{A}\\mathbf{B} +\\mathbf{B}^2$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Find the resulting vector $\\mathbf{b}$ if the given vector $\\mathbf{a} = \\langle x, y \\rangle$ is rotated through the indicated angle\n",
    "\n",
    "  $\\mathbf{a} = \\langle 1, 1 \\rangle$, $~$ $\\theta=\\pi/2$\n",
    "  \n",
    "  $~$\n",
    "\n",
    "* Verify that the quadratic form $ax^2 +bxy +cy^2$ is the same as\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " x & y \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    " a & \\frac{1}{2}b \\\\ \n",
    " \\frac{1}{2}b & c \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\ y \n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8JeFdj0AOrz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.2$~$ Systems of Linear Algebraic Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **General Form**\n",
    "\n",
    "  A system of $m$ linear equations in $n$ unknowns has the general form\n",
    "  \n",
    "  >$\n",
    "  \\begin{align*}\n",
    "    a_{11} x_1 +a_{12} x_2 + \\cdots +a_{1n} x_n &= b_1\\\\ \n",
    "    a_{21} x_1 +a_{22} x_2 + \\cdots +a_{2n} x_n &= b_2\\\\ \n",
    "     &\\;\\,\\vdots \\\\ \n",
    "    a_{m1} x_1 +a_{m2} x_2 + \\cdots +a_{mn} x_n &= b_m\n",
    "  \\end{align*}  \n",
    "  $\n",
    "  \n",
    "  The **coefficients** of the unknowns can be abbreviated as $a_{ij}$. \n",
    "  The numbers $b_1, b_2, \\cdots, b_m$ are called the **constants** of the system. \n",
    "  If all the constants are zero, the system is said to be **homogeneous**, otherwise it is\n",
    "  **nonhomogeneous**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQUeDgEtAOr0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* A linear system of equations is said to be **consistent** $~$if it has at least one solution and\n",
    "  **inconsistent** $~$if it has no solutions. $~$If a linear system is consistent, $~$it has either\n",
    "  \n",
    "  * a unique solution (that is, precisely one solution), or\n",
    "  * infinitely many solutions\n",
    "\n",
    "  $~$\n",
    "  \n",
    "  <img src=\"figures/ch08_figure01.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Augmented Matrix**\n",
    "\n",
    ">$\n",
    "  \\left(\\begin{array}{cccc|c}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} & b_1\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} & b_2\\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots & \\vdots\\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn} & b_m\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qr2EmQglAOr2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* A system can be solved with **elementary operations** (**row reduction** for matrices)\n",
    "  on an augmented matrix\n",
    "  \n",
    ">| Elementary Operations | Meaning |\n",
    "|:----------------------|:--------|\n",
    "| $R_{ij}$        | Interchange rows $i$ and $j$                             |\n",
    "| $cR_{i}$        | Multiply the $i$-th row by the nonzero constant $c$      | \n",
    "| $cR_{i}+R_{j}$  | Multiply the $i$-th row by $c$ and add to the $j$-th row |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AedryhQVAOr3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In the **Gaussian elimination**, $~$we row-reduce the augmented matrix until we arrive \n",
    "  at a row-equivalent augmented matrix in **row-echelon form**\n",
    "  \n",
    "  * <font color='green'>The first nonzero entry in a nonzero row is a $1$</font>\n",
    "\n",
    "  * <font color='blue'>In consecutive nonzero rows, $~$the first entry $1$ in the lower row appears to the right of the $1$ in the higher row</font>\n",
    "  \n",
    "  * <font color='green'>Rows consisting of all zeros are at the bottom of the matrix</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Solve\n",
    "  \n",
    "  >$\n",
    "  \\begin{pmatrix}\n",
    "    2 & 6 & \\;\\; 1\\\\ \n",
    "    1 & 2 & -1\\\\ \n",
    "    5 & 7 & -4\n",
    "  \\end{pmatrix}\n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\\\\ \n",
    "    x_3\n",
    "  \\end{pmatrix}=\n",
    "  \\begin{pmatrix}\n",
    "    \\;\\;7\\\\ \n",
    "    -1\\\\ \n",
    "    \\;\\;9\n",
    "  \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using row operations on the augmented matrix, $~$we obtain\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    2 & 6 &  1 & 7\\\\ \n",
    "    1 & 2 & -1 & -1\\\\ \n",
    "    5 & 7 & -4 & 9\n",
    "  \\end{array}\\right) \n",
    "  \\overset{R_{12}}{\\Longrightarrow}  \n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    2 & 6 &  1 & 7\\\\ \n",
    "    5 & 7 & -4 & 9\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\begin{align*}\n",
    "           -2R_1 +&R_2 \\\\ \n",
    "           -5R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 2 &  3 & 9\\\\ \n",
    "    0 & -3 & 1 & 14\n",
    "  \\end{array}\\right)} \n",
    "  $\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\overset{\\frac{1}{2}R_2}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & -3 & 1 & 14\n",
    "  \\end{array}\\right)\n",
    "  \\overset{3R_2 +R_3}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & \\;\\frac{11}{2} & \\;\\frac{55}{2}\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\frac{2}{11}R_3}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWqLrPsJAOr5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "  The last matrix is in row-echelon form. $~$We can make the last matrix above to be in reduced row-echelon form\n",
    "\n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 & -1 & -1\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)  \n",
    "  \\overset{-2R_2 +R_1}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & -4 & -10\\\\   \n",
    "    0 & 1 &  \\frac{3}{2} & \\frac{9}{2} \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)   \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_3 +&R_1 \\\\ \n",
    "          -\\frac{3}{2}R_3 +&R_2 \n",
    "           \\end{align*}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 0 & 10\\\\   \n",
    "    0 & 1 & 0 & -3 \\\\\n",
    "    0 & 0 & 1 & 5\n",
    "  \\end{array}\\right)} \n",
    "  $\n",
    "  \n",
    "  We see that the solution is $x_1=10$, $\\text{ }x_2=-3$, $\\text{ }x_3=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-_ah9OqAOr7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Solve\n",
    "  \n",
    "  >$\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    1 & 3 & -2\\\\ \n",
    "    4 & 1 & 3\\\\ \n",
    "    2 & -5 & 7\n",
    "  \\end{array}\\right) \n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\\\\ \n",
    "    x_3\n",
    "  \\end{pmatrix}=\n",
    " \\left(\\begin{array}{r}\n",
    "    -7\\\\ \n",
    "     5\\\\ \n",
    "    19\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using row operations on the augmented matrix, we obtain\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    4 & 1 &  3 & 5\\\\ \n",
    "    2 & -5 & 7 & 19\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_1 +&R_2 \\\\ \n",
    "           -2R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    0 & -11 & 11 & 33\\\\ \n",
    "    0 & -11 & 11 & 33\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -R_2 +&R_3 \\\\ \n",
    "           -\\frac{1}{11}&R_2 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr:r|r}\n",
    "    1 & 3 & -2 & -7\\\\ \n",
    "    0 & 1 & -1 & -3\\\\ \\hdashline\n",
    "    0 & 0 & 0 & {\\color{Red}0 }\n",
    "  \\end{array}\\right)} \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  \n",
    "  In this case, $~$the last matrix implies that the original system of three equations is really equivalent to\n",
    "  two equations. \n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\overset{-3R_2 +R_1}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr:r|r}\n",
    "    1 & 0 & 1 & 2\\\\ \n",
    "    0 & 1 & -1 & -3\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)}   \n",
    "  $\n",
    "  \n",
    "  If we let $x_3=t$, $x_1=-t +2$ and $x_2=t -3$, $~$then we see that the system has infinitely many solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPa9d9zvAOr8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Solve\n",
    "  \n",
    "  >$\n",
    "  \\left(\\begin{array}{rr}\n",
    "    1 & 1 \\\\ \n",
    "    4 & -1 \\\\ \n",
    "    2 & -3\n",
    "  \\end{array}\\right) \n",
    "  \\begin{pmatrix}\n",
    "    x_1\\\\ \n",
    "    x_2\n",
    "  \\end{pmatrix}=\n",
    " \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "   -6\\\\ \n",
    "    8\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Using row operations on the augmented matrix, $~$we obtain\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    4 & -1 & -6\\\\ \n",
    "    2 & -3 & 8\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -4R_1 +&R_2 \\\\ \n",
    "           -2R_1 +&R_3 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    0 & -5 & -10\\\\ \n",
    "    0 & -5 & 6\n",
    "  \\end{array}\\right) \n",
    "  \\overset{\\begin{align*}\n",
    "           -R_2 +&R_3 \\\\ \n",
    "           -\\frac{1}{5}R_2 \n",
    "           \\end{align*}}\n",
    "  {\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 & 1 & 1\\\\ \n",
    "    0 & 1 & 2\\\\ \\hdashline\n",
    "    0 & 0 & {\\color{Red}{16}}\n",
    "  \\end{array}\\right)}  \n",
    "  $\n",
    "  \n",
    "  The system has no solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "KEajEf5pAOr_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* A **homogeneous system** of linear equations is **always consistent**. The solution consisting of all zeros is called the **trivial solution**. A homogeneous system either possesses only the trivial solution or possesses the trivial solution along with infinitely many nontrivial solutions\n",
    "\n",
    "* <font color='blue'>**A homogeneous system possesses nontrivial solutions if the number $m$ of equations is less than the number $n$ of unknowns $(m<n)$**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Find the positive integers $x_1$, $x_2$, $x_3$, and $x_4$ so that\n",
    "\n",
    "> $x_1 \\mathrm{C_2H_6} +x_2 \\mathrm{O_2} \\rightarrow x_3 \\mathrm{CO_2} +x_4 \\mathrm{H_2O}$\n",
    "\n",
    "Because the number of atoms of each element must be the same on each side of the last equation, $~$we have:\n",
    "\n",
    ">| Atom |      |\n",
    "| ---- | :--- |\n",
    "|$\\mathrm{C}$ |$2x_1=x_3$       |\n",
    "|$\\mathrm{H}$ |$6x_1=2x_4$      |\n",
    "|$\\mathrm{O}$ |$2x_2=2x_3 +x_4$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6f5yFXGEAOsA",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  $${\\scriptsize\n",
    "  \\left(\\begin{array}{rrrr|r}\n",
    "    2 & 0 & -1 &  0 & 0\\\\   \n",
    "    6 & 0 &  0 & -2 & 0\\\\\n",
    "    0 & 2 & -2 & -1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\begin{align*}\n",
    "             &R_{12} \\\\ \n",
    "             &R_{23} \n",
    "           \\end{align*}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrrr|r}\n",
    "    6 & 0 &  0 & -2 & 0\\\\\n",
    "    0 & 2 & -2 & -1 & 0\\\\\n",
    "    2 & 0 & -1 &  0 & 0  \n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr:r|r} \n",
    "    1 & 0 & 0 & -\\frac{1}{3} & 0\\\\   \n",
    "    0 & 1 & 0 & -\\frac{7}{6} & 0\\\\\n",
    "    0 & 0 & 1 & -\\frac{2}{3} & 0\n",
    "  \\end{array}\\right)}\n",
    "  $$\n",
    "  \n",
    "  Then when we let  $x_4=t$, $x_1=\\frac{1}{3}t$, $x_2=\\frac{7}{6}t$, $x_3=\\frac{2}{3}t$. $~$If we pick $t=6$, \n",
    "  $x_1=2$, $x_2=7$, $x_3=4$, $x_4=6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ur0f0NOAOsB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.2\n",
    "\n",
    "* Use either Gaussian elimination or Gauss-Jordan elimination to solve the given system or show that no solution exists\n",
    "\n",
    "  $\\begin{align*}\n",
    "   \\phantom{-}&x_1 - x_2 = 11\\\\ \n",
    "   &4x_1 +3x_2 =-5 \n",
    "  \\end{align*}$\n",
    "\n",
    "  $\\begin{align*}\n",
    "   \\phantom{-}&9x_1 +3x_2 = -5\\\\ \n",
    "   &2x_1 +x_2 = -1 \n",
    "  \\end{align*}$\n",
    "\n",
    "  $\\begin{align*}\n",
    "    \\phantom{-}&x_1 -x_2 -x_3 = -3\\\\ \n",
    "    &2x_1 +3x_2 +5x_3 = 7\\\\\n",
    "    &x_1 -2x_2 +3x_3 =-11 \n",
    "  \\end{align*}$\n",
    "\n",
    "  $\\begin{align*}\n",
    "    \\phantom{-}&x_1 +x_2 +x_3 = 0\\\\ \n",
    "    &x_1 +x_2 +3x_3 =0 \n",
    "  \\end{align*}$\n",
    "\n",
    "  $\\begin{align*}\n",
    "    &x_1 -x_2 -x_3 = 8\\\\ \n",
    "    &x_1 -x_2 +x_3 = 3\\\\\n",
    "    -&x_1 +x_2 +x_3 = 4 \n",
    "  \\end{align*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Balance the given chemical equation:\n",
    "  \n",
    "  $\\mathrm{C}_5\\mathrm{H}_8 +\\mathrm{O}_2 \\rightarrow \\mathrm{CO}_2 + \\mathrm{H}_2\\mathrm{O}$\n",
    "\n",
    "  $\\mathrm{Cu} + \\mathrm{HNO}_3 \\rightarrow \\mathrm{Cu(NO}_3\\mathrm{)}_2 + \\mathrm{H}_2\\mathrm{O} +\\mathrm{NO}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Compute the given product for an arbitrary $~3 \\times 3$ matrix $\\mathbf{A}$\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 0 & 1 & 0\\\\ \n",
    " 1 & 0 & 0\\\\ \n",
    " 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    " 1 & 0 & 0\\\\ \n",
    " 0 & 1 & 0\\\\ \n",
    " 0 & c & 1\n",
    "\\end{pmatrix} \\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-_MlQJ_AOsB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.3 Rank of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRRJSu_5AOsC",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **rank** of an $m \\times n$ matrix $\\mathbf{A}$, $~\\mathrm{rank}(\\mathbf{A})$, $~$is \n",
    "  **the maximum number of linearly independent row vectors**. If a matrix $\\mathbf{A}$ is now equivalent to\n",
    "  a row-echelon form $\\mathbf{B}$, $~$then\n",
    "\n",
    "  * the row space of $\\mathbf{A}$ = the row space of $\\mathbf{B}$\n",
    "  * the nonezero rows of $\\mathbf{B}$ form a basis for the row space of $\\mathbf{A}$, $~$and\n",
    "  * $\\mathrm{rank}(\\mathbf{A})$ = the number of nonzero rows in $\\mathbf{B}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "zjazwL2vAOsD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* <font color='red'>**Consistency of** $~\\mathbf{A}\\mathbf{x}=\\mathbf{b}$</font>\n",
    "\n",
    "  A linear system of equations $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ is <font color='red'>consistent if and only if $~\\mathrm{rank}(\\mathbf{A})=\\mathrm{rank}(\\mathbf{A}|\\mathbf{b})$</font>. \n",
    "\n",
    "  Suppose a linear system $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ with $m$ equations and $n$ unknowns is consistent.\n",
    "  $~$If $\\mathrm{rank}(\\mathbf{A})=r\\leq n$, then the solution of the system contains $n -r$ parameters. This means that we have the unique solution when $r=n$.\n",
    "\n",
    "  >${\\scriptsize\n",
    "  \\left(\\begin{array}{cccc|c}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} & b_1\\\\ \n",
    "    a_{21} & a_{22} & \\ddots & a_{2n} & b_2\\\\ \n",
    "    \\vdots & \\ddots & \\ddots & \\vdots & \\vdots\\\\ \n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn} & b_m\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{cccc:ccc|c}\n",
    "    1      & a_{12}' & \\cdots & a_{1{\\color{red}r}}'& a_{1r+1}' & \\cdots   & a_{1n}' & b_1' \\\\ \n",
    "    0      & 1       & \\ddots & \\vdots & a_{2r+1}' & \\ddots   & a_{2n}' & b_2' \\\\\n",
    "    \\vdots & \\ddots  & \\ddots & \\vdots & \\vdots    & \\ddots   & \\vdots  & \\vdots \\\\    \n",
    "    0      & \\cdots  & 0      & 1      & a_{{\\color{red}r}r+1}' & \\cdots   & a_{rn}' & b_r' \\\\ \\hdashline     \n",
    "    0      & 0       & 0      & 0      & 0         & 0        & 0       & {\\color{red} 0} \\\\\n",
    "    \\vdots & \\vdots  & \\vdots & \\vdots & \\vdots    & \\vdots   & \\vdots  & {\\color{red} \\vdots} \\\\    \n",
    "    0      & 0       & 0      & 0      & 0         & 0        & 0       & {\\color{red} 0}    \n",
    "  \\end{array}\\right) }\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  <img src=\"figures/ch08_figure02.png?\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "lzKg3R3KAOsD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.3\n",
    "\n",
    "* Find the rank of the given matrix\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    "    3 & -1 \\\\ \n",
    "    1 &\\phantom{-}3 \n",
    "   \\end{pmatrix}$\n",
    "   \n",
    "  $\\begin{pmatrix}\n",
    "     \\phantom{-}2 & \\phantom{-}1 & \\phantom{-}3 \\\\ \n",
    "     \\phantom{-}6 & \\phantom{-}3 & \\phantom{-}9 \\\\ \n",
    "     -1 & -\\frac{1}{2} & -\\frac{3}{2} \n",
    "    \\end{pmatrix}$\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    "     1 & 1 & 1\\\\ \n",
    "     1 & 0 & 4\\\\ \n",
    "     1 & 4 & 1\n",
    "   \\end{pmatrix}$\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    "    0 & 2 & 4 & 2 & 2\\\\ \n",
    "    4 & 1 & 0 & 5 & 1\\\\ \n",
    "    2 & 1 & \\frac{2}{3} & 3 & \\frac{1}{3} \\\\ \n",
    "    6 & 6 & 6 & 12 & 0 \n",
    "   \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Determine whether the given set of vectors is linearly dependent or linearly independent\n",
    "\n",
    "  $\\mathbf{u}_1 = \\langle 1, 2, 3 \\rangle, \\;\\mathbf{u}_2 = \\langle 1, 0, 1 \\rangle, \\; \\mathbf{u}_3 = \\langle 1, -1, 5 \\rangle$\n",
    "\n",
    "  $\\mathbf{u}_1 = \\langle 1, -1, 3, -1 \\rangle, \\;\\mathbf{u}_2 = \\langle 1, -1, 4, 2 \\rangle, \\; \\mathbf{u}_3 = \\langle 1, -1, 5, 7 \\rangle$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose the system $\\mathbf{Ax}=\\mathbf{b}~$ is consistent and $~\\mathbf{A}$ is a $5\\times 8~$ matrix and $~\\mathrm{rank}(\\mathbf{A})=3$. $~$How many parameters does the solution of the system have?\n",
    "\n",
    "  $~$\n",
    "  \n",
    "* Let $\\mathbf{A}$ be a nonzero $4 \\times 6~$ matrix.\n",
    "\n",
    "  (1) $~$What is the maximum rank that $~\\mathbf{A}~$ can have?\n",
    "  \n",
    "  (2) $~$If $\\mathrm{rank}(\\mathbf{A}|\\mathbf{b})=2$, $~$then for what value(s) of $\\mathrm{rank}(\\mathbf{A})~$ is the system $~\\mathbf{Ax}=\\mathbf{b}~$, $~\\mathbf{b}\\neq \\mathbf{0}~$, inconsistent? Consistent?\n",
    " \n",
    "  (3) $~$If $\\mathrm{rank}(\\mathbf{A})=3~$, $~$then how many parameters does the solution of the system $~\\mathbf{Ax}=\\mathbf{0}~$ have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let $\\mathbf{v}_1$, $\\mathbf{v}_2$, and $~\\mathbf{v}_3~$ be the first, second, and third column vectors, respectively, of the matrix\n",
    "\n",
    "  $\\mathbf{A} = \\begin{pmatrix}\n",
    " \\phantom{-}2 & 1 & 7\\\\ \n",
    " \\phantom{-}1 & 0 & 2\\\\ \n",
    " -1 & 5 & 13 \n",
    "\\end{pmatrix}$\n",
    "\n",
    "  What can we conclude about $\\mathrm{rank} (\\mathbf{A})$ from the observation $2\\mathbf{v}_1 +3\\mathbf{v}_2 -\\mathbf{v}_3=\\mathbf{0}$?\n",
    "  \n",
    "> <font color='red'>The fact that the column and row ranks of any matrix are equal is fundamental in linear algebra.</font>  As Gaussian elimination proceeds by elementary row operations, the reduced row echelon form of a matrix has the same row rank and the same column rank as the original matrix. Further elementary column operations allow putting the matrix in the form of an identity matrix possibly bordered by rows and columns of zeros. Again, this changes neither the row rank nor the column rank. It is immediate that both the row and column ranks of this resulting matrix is the number of its nonzero entries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Obp_SEjDAOsE",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.4 Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vRVtE0lAOsF",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Determinant of a $2 \\times 2$ Matrix**\n",
    "\n",
    ">$\\mathrm{det}(\\mathbf{A})=\n",
    "   \\begin{vmatrix}\n",
    "     a_{11} & a_{12}\\\\ \n",
    "     a_{21} & a_{22}\n",
    "   \\end{vmatrix}=a_{11}a_{22}-a_{12}a_{21}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzVenxnLAOsG",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Determinant of a $3 \\times 3$ Matrix**\n",
    "\n",
    ">$\n",
    "   \\mathrm{det}(\\mathbf{A})=\n",
    "   \\begin{vmatrix}\n",
    "     a_{11} & a_{12} & a_{13}\\\\ \n",
    "     a_{21} & a_{22} & a_{23}\\\\\n",
    "     a_{31} & a_{32} & a_{33}\n",
    "   \\end{vmatrix}={\\scriptsize\n",
    "   a_{11}(-1)^{1+1} \n",
    "   \\begin{vmatrix}\n",
    "     a_{22} & a_{23}\\\\ \n",
    "     a_{32} & a_{33}\n",
    "   \\end{vmatrix} +\n",
    "   a_{12}(-1)^{1+2} \n",
    "   \\begin{vmatrix}\n",
    "     a_{21} & a_{23}\\\\ \n",
    "     a_{31} & a_{33}\n",
    "   \\end{vmatrix} +\n",
    "   a_{13}(-1)^{1+3} \n",
    "   \\begin{vmatrix}\n",
    "     a_{21} & a_{22}\\\\ \n",
    "     a_{31} & a_{32}\n",
    "   \\end{vmatrix}} \n",
    "  $   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Determinant of a $n\\times n$ Matrix**\n",
    "\n",
    "  >$\\mathrm{det}\\,\\mathbf{A} = \\sum (-1)^h a_{1l_1} a_{2l_2} \\cdots a_{nl_n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-ReEQwTAOsG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Cofactor and Minor**\n",
    "\n",
    "  The **cofactor of $a_{ij}$** is the determinant\n",
    "  \n",
    "  >$C_{ij}=(-1)^{i +j} M_{ij}$\n",
    "  \n",
    "  where $M_{ij}$ is the determinant of the submatrix obtained by deleting the $i$-th row \n",
    "  and the $j$-th column of $\\mathbf{A}$. The determinant $M_{ij}$ is called a **minor determinant** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kobviaIDAOsH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Cofactor Expansion of a Determinant (Laplace Development)**\n",
    "\n",
    "  Let $\\mathbf{A}=\\left(a_{ij}\\right)_{n \\times n}$ be an $n \\times n$ matrix. $~$For each $1 \\leq i \\leq n$, \n",
    "  $~$**the cofactor expansion of $\\mathrm{det}(\\mathbf{A})$ along the $i$-th row** is\n",
    "  \n",
    "  >$\\displaystyle\n",
    "  \\mathrm{det}(\\mathbf{A})=\\sum_{k=1}^na_{ik}C_{ik}$\n",
    "  \n",
    "  For each $1 \\leq j \\leq n$, $~$**the cofactor expansion of $\\mathrm{det}(\\mathbf{A})$ along the $j$-th column** is\n",
    "  \n",
    "  >$\\displaystyle\n",
    "  \\mathrm{det}(\\mathbf{A})=\\sum_{k=1}^na_{kj}C_{kj}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktBzeTZZAOsI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.4\n",
    "\n",
    "* Suppose\n",
    "\n",
    "  $\\mathbf{A} = \\begin{pmatrix}\n",
    "    \\phantom{-}2 & \\phantom{-}3 & 4\\\\ \n",
    "    \\phantom{-}1 & -1 & 2\\\\ \n",
    "     -2 & \\phantom{-}3 & 5 \n",
    "   \\end{pmatrix}$\n",
    "   \n",
    "   Evaluate the indicated minor determinant or cofactor\n",
    "   \n",
    "   1. $~M_{12}~$ 2. $~M_{32}~$ 3. $~C_{13}~$ 4. $~C_{22}$\n",
    "   \n",
    "   $~$\n",
    "\n",
    "* Evaluate the determinant of the matrix\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " \\phantom{-}3 & 5 \\\\ \n",
    " -1 & 4 \n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 1 - \\lambda & 3 \\\\ \n",
    " 2 & 2 - \\lambda \n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Evaluate the determinant of the given matrix by cofactor expansion\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " -2 & -1 & 4\\\\ \n",
    " -3 & \\phantom{-}6 & 1\\\\ \n",
    " -3 & \\phantom{-}4 & 8\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 1 & 1 & 1\\\\ \n",
    " x & y & z\\\\ \n",
    " 2 & 3 & 4\n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0tgTJogAOsI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.5 Properties of Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9B845k0KAOsJ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If $\\mathbf{A}^T$ is the transpose of the $n \\times n$ matrix $\\mathbf{A}$, \n",
    "  $~$then <font color='blue'>$\\mathrm{det}(\\mathbf{A}^T)=\\mathrm{det}(\\mathbf{A})$</font>\n",
    "  \n",
    "  $\\begin{vmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{21} & a_{22} & a_{23}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix} =\n",
    "\\begin{vmatrix}\n",
    " a_{11} & a_{21} & a_{31}\\\\ \n",
    " a_{12} & a_{22} & a_{32}\\\\ \n",
    " a_{13} & a_{23} & a_{33}\n",
    "\\end{vmatrix}$\n",
    "\n",
    "  $~$\n",
    "  \n",
    "* <font color='blue'>If any two rows (columns) of an $n \\times n$ matrix $\\mathbf{A}$ are the same, $~$then $\\mathrm{det}(\\mathbf{A})=0$</font>\n",
    "\n",
    "  $\\begin{vmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* <font color='blue'>If all the entries in a row (column) of an $n \\times n$ matrix $\\mathbf{A}$ are zero, $~$then $\\mathrm{det}(\\mathbf{A})=0$</font>\n",
    "\n",
    "  $\\begin{vmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " 0 & 0 & 0\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix} = 0$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* <font color='green'>If $\\mathbf{B}$ is the matrix obtained by interchanging any two rows (columns) of an $n \\times n$ matrix $\\mathbf{A}$, $~$then $\\mathrm{det}(\\mathbf{B})=-\\mathrm{det}(\\mathbf{A})$</font>\n",
    "\n",
    "  $\\begin{vmatrix}\n",
    " a_{21} & a_{22} & a_{23}\\\\ \n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix} = -\n",
    "\\begin{vmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{21} & a_{22} & a_{23}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* <font color='green'>If $\\mathbf{B}$ is the matrix obtained by multiplying a row (column) by a nonzero real number $k$,\n",
    "  $~$then $\\mathrm{det}(\\mathbf{B})=k\\mathrm{det}(\\mathbf{A})$</font>\n",
    "  \n",
    "  $\\begin{vmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " ka_{21} & ka_{22} & ka_{23}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix} = k\n",
    "\\begin{vmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{21} & a_{22} & a_{23}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix}$\n",
    "\n",
    "  $~$\n",
    "  \n",
    "* <font color='blue'>If $\\mathbf{A}$ and $\\mathbf{B}$ are both $n \\times n$ matrices, $~$then \n",
    "  $\\mathrm{det}(\\mathbf{AB})=\\mathrm{det}(\\mathbf{A})\\cdot \\mathrm{det}(\\mathbf{B})$</font>\n",
    "  \n",
    "  $\\begin{vmatrix} \n",
    "\\begin{pmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{21} & a_{22} & a_{23}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    " b_{11} & b_{12} & b_{13}\\\\ \n",
    " b_{21} & b_{22} & b_{23}\\\\ \n",
    " b_{31} & b_{32} & b_{33}\n",
    "\\end{pmatrix}\n",
    "\\end{vmatrix}\n",
    "=\n",
    "\\begin{vmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{21} & a_{22} & a_{23}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix}\n",
    "\\begin{vmatrix}\n",
    " b_{11} & b_{12} & b_{13}\\\\ \n",
    " b_{21} & b_{22} & b_{23}\\\\ \n",
    " b_{31} & b_{32} & b_{33}\n",
    "\\end{vmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* <font color='blue'>Suppose $\\mathbf{B}$ is the matrix obtained from an $n \\times n$ matrix $\\mathbf{A}$ by multiplying the entries\n",
    "  in a row (column) by a nonzero real number $k$ and adding the result to the corresponding entries in another\n",
    "  row (column). $~$Then $\\mathrm{det}(\\mathbf{B})=\\mathrm{det}(\\mathbf{A})$</font>\n",
    "  \n",
    "  $\\begin{vmatrix} \n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{21} & a_{22} & a_{23}\\\\ \n",
    " ka_{21} +a_{31} & ka_{22}+a_{32} & ka_{23} +a_{33}\n",
    "\\end{vmatrix}\n",
    "=\n",
    "\\begin{vmatrix}\n",
    " a_{11} & a_{12} & a_{13}\\\\ \n",
    " a_{21} & a_{22} & a_{23}\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix}$\n",
    "\n",
    "  $~$\n",
    "  \n",
    "* If $\\mathbf{A}$ is an $n \\times n$ triangular matrix, $~$then $\\mathrm{det}(\\mathbf{A})=a_{11} a_{22}\\cdots a_{nn}$\n",
    "\n",
    "  $\\begin{vmatrix}\n",
    " a_{11} & 0 & 0\\\\ \n",
    " a_{21} & a_{22} & 0\\\\ \n",
    " a_{31} & a_{32} & a_{33}\n",
    "\\end{vmatrix} = a_{11} a_{22} a_{33}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKsN2Dy-AOsK",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Alien Cofactors**\n",
    "\n",
    "Suppose $\\mathbf{A}$ is an $n \\times n$ matrix. If $a_{i1}, a_{i2}, \\cdots, a_{in}$ are the entries\n",
    "in the $i$-th row and $C_{p1}, C_{p2}, \\cdots, C_{pn}$ are the cofactors of the entries in the $p$-th row, $~$then\n",
    "\n",
    ">$\\displaystyle\\sum_{k=1}^n a_{ik}C_{pk}=0\\;\\;\\text{for}\\; i \\neq p$\n",
    "\n",
    "If $a_{1j}, a_{2j}, \\cdots, a_{nj}$ are the entries\n",
    "in the $j$-th column and $C_{1p}, C_{2p}, \\cdots, C_{np}$ are the cofactors of the entries in the $p$-th column, $~$then\n",
    "\n",
    ">$\\displaystyle\\sum_{k=1}^n a_{kj}C_{kp}=0\\;\\;\\text{for}\\; j \\neq p$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjh8SE5nAOsK",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.5\n",
    "\n",
    "* State the appropriate theorem(s) in this section that justifies the given equality\n",
    "  \n",
    "  $\\begin{vmatrix}\n",
    " 1 & 2\\\\ \n",
    " 3 & 4\n",
    "\\end{vmatrix} = -\n",
    "\\begin{vmatrix}\n",
    " 3 & 4\\\\\n",
    " 1 & 2 \n",
    "\\end{vmatrix}$\n",
    "\n",
    "  $\\begin{vmatrix}\n",
    " -5 & \\phantom{-}6\\\\ \n",
    " \\phantom{-}2 & -8\n",
    "\\end{vmatrix} =\n",
    "\\begin{vmatrix}\n",
    " \\phantom{-}1 & \\phantom{-}6\\\\\n",
    " -6 & -8 \n",
    "\\end{vmatrix}$\n",
    "\n",
    "  $\\begin{vmatrix}\n",
    " 1 & 2 & \\phantom{--}3\\\\ \n",
    " 4 & 2 & \\phantom{-}18\\\\\n",
    " 5 & 9 & -12\n",
    "\\end{vmatrix} = 6\n",
    "\\begin{vmatrix}\n",
    " 1 & 2 & \\phantom{-}1\\\\ \n",
    " 2 & 1 & \\phantom{-}3\\\\\n",
    " 5 & 9 & -4\n",
    "\\end{vmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Evaluate the determinant of the given matrix using the result\n",
    "\n",
    "  $$\\begin{vmatrix}\n",
    " a_1 & a_2 & a_3\\\\ \n",
    " b_1 & b_2 & b_3\\\\\n",
    " c_1 & c_2 & c_3\n",
    "\\end{vmatrix} = 5$$\n",
    "\n",
    "  (a) $~$ $\\mathbf{A} =\n",
    "\\begin{pmatrix}\n",
    " a_3 & a_2 & a_1\\\\ \n",
    " b_3 & b_2 & b_1\\\\ \n",
    " c_3 & c_2 & c_1\n",
    "\\end{pmatrix}$\n",
    "  \n",
    "  (b) $~$ $\\mathbf{A} =\n",
    "\\begin{pmatrix}\n",
    " 2a_1 & a_2 & a_3\\\\ \n",
    " 6b_1 & 3b_2 & 3b_3\\\\ \n",
    " 2c_1 & c_2 & c_3\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  (c) $~$ $\\mathbf{A} =\n",
    "\\begin{pmatrix}\n",
    " 4a_1 -2a_3 & a_2 & a_3\\\\ \n",
    " 4b_1 -2b_3 & b_2 & b_3\\\\ \n",
    " 2c_1 -c_3 & \\frac{1}{2}c_2 & \\frac{1}{2}c_3\n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Evaluate the determinant of the given matrix without expanding by cofactors\n",
    "\n",
    "  $\\mathbf{B} =\n",
    "\\begin{pmatrix}\n",
    " 0 & 0 & a_{13}\\\\ \n",
    " 0 & a_{22} & a_{23} \\\\ \n",
    " a_{31} & a_{32} & a_{33} \n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $\\mathbf{C} =\n",
    "\\begin{pmatrix}\n",
    " 0 & 7 & \\phantom{-}0\\\\ \n",
    " 4 & 0 & \\phantom{-}0\\\\ \n",
    " 0 & 0 & -2\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}$ is an $n \\times n$ matrix such that $\\mathbf{A}^2 = \\mathbf{I}$. $~$Then show that $\\mathrm{det}\\,\\mathbf{A}=\\pm 1$\n",
    "\n",
    "* Suppose $\\mathbf{A}$ is an $n \\times n$ matrix such that $\\mathbf{A}^2 = \\mathbf{A}$. $~$Then show that either $\\mathrm{det}\\,\\mathbf{A} = 0$ or $\\mathrm{det}\\,\\mathbf{A} = 1$\n",
    "\n",
    "* If $\\mathbf{A}$ and $\\mathbf{B}$ are an $n \\times n$ matrices, $~$then prove or disprove that $\\mathrm{det}\\,\\mathbf{AB} = \\mathrm{det}\\,\\mathbf{BA}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "* Consider the matrix\n",
    "\n",
    "  $\\mathbf{A} =\n",
    "\\begin{pmatrix}\n",
    " 1 & 1 & 1\\\\ \n",
    " x & y & z\\\\ \n",
    " y+z & x+z & x+y\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  Without expanding, $~$show that $\\mathrm{det}\\, \\mathbf{A}=0$\n",
    "  \n",
    "  $~$\n",
    "\n",
    "* Evaluate \n",
    "\n",
    "  $\\begin{vmatrix}\n",
    " 1 & 1 & 1 & 1\\\\ \n",
    " a & b & c & d\\\\ \n",
    " a^2 & b^2 & c^2 & d^2\\\\ \n",
    " a^3 & b^3 & c^3 & d^3\n",
    "\\end{vmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ig3cmwbLAOsL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.6 Inverse of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If $\\mathbf{A}$ is an $n \\times n$ matrix and there exists an $n \\times n$ matrix $\\mathbf{B}$ such that\n",
    "\n",
    "  >$\\mathbf{A}\\mathbf{B}=\\mathbf{B}\\mathbf{A}=\\mathbf{I}$,\n",
    "  \n",
    "  then $\\mathbf{A}$ is said to be **nonsingular** or **invertible** and $\\mathbf{B}$ \n",
    "  is the **inverse** of $\\mathbf{A}$\n",
    "\n",
    "* An $n \\times n$ matrix that has no inverse is called **singular**. If $\\mathbf{A}$ is nonsingular, \n",
    "  $~$its inverse is denoted by $\\mathbf{B}=\\mathbf{A}^{-1}$\n",
    "  \n",
    "* **Properties of the Inverse**\n",
    "\n",
    "  Let $\\mathbf{A}$ and $\\mathbf{B}~$ be nonsingular matrices. Then\n",
    "  \n",
    "  * $\\left(\\mathbf{A}^{-1}\\right)^{-1}=\\mathbf{A}$\n",
    "  \n",
    "  * $\\left(\\mathbf{A}\\mathbf{B}\\right)^{-1}=\\mathbf{B}^{-1}\\mathbf{A}^{-1}$\n",
    "  \n",
    "  * $\\left(\\mathbf{A}^T\\right)^{-1}=\\left(\\mathbf{A}^{-1}\\right)^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "colab_type": "text",
    "id": "YbBM3KKkAOsM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Adjoint Matrix**\n",
    "\n",
    "  >$\\displaystyle\n",
    "   \\mathrm{adj}(\\mathbf{A})=\n",
    "   \\begin{pmatrix}\n",
    "     C_{11} & C_{12} & \\cdots & C_{1n}\\\\ \n",
    "     C_{21} & C_{22} & \\cdots & C_{2n}\\\\ \n",
    "     \\vdots &        &        & \\vdots\\\\ \n",
    "     C_{n1} & C_{n2} & \\cdots & C_{nn}\n",
    "   \\end{pmatrix}^T   \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Finding the Inverse**\n",
    "  \n",
    "  Let $\\mathbf{A}$ be an $n \\times n$ matrix. $~$If $\\mathrm{det}(\\mathbf{A})\\neq 0$ (**nonsingular**), then\n",
    "  \n",
    "  >$\\displaystyle\n",
    "   \\mathbf{A}^{-1}=\\frac{\\mathrm{adj}(\\mathbf{A})}{\\mathrm{det}(\\mathbf{A})}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  or\n",
    "\n",
    "  > ![inverse](figures/ch08_figure03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JgDyrmrTAOsM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Using the Inverse to Solve Systems**\n",
    "\n",
    "  The coefficient matrix $\\mathbf{A}$ is $n \\times n$. In particular, $~$if $\\mathbf{A}$ is nonsingular,\n",
    "  $~$the system $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ can be solved by\n",
    "  \n",
    "  >$\\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}$\n",
    "  \n",
    "  A homogeneous system of $n$ linear equations in $~n$ unknowns <font color='blue'>$\\mathbf{A}\\mathbf{x}=\\mathbf{0}$</font> $~$has\n",
    "  \n",
    "  * only the trivial solution if and only if $\\mathbf{A}$ is nonsingular\n",
    "  \n",
    "  * <font color='blue'>a nontrivial solution if and only if $\\mathbf{A}$ is singular</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDOUyUWgAOsN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.6\n",
    "\n",
    "* Verify that the matrix $\\mathbf{B}$ is the inverse of the matrix $\\mathbf{A}$\n",
    "\n",
    "  $\\mathbf{A}=\\begin{pmatrix}\n",
    " 1 & \\frac{1}{2} \\\\ \n",
    " 2 & \\frac{3}{2}\n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\mathbf{B}=\\begin{pmatrix}\n",
    " \\phantom{-}3 & -1 \\\\ \n",
    " -4 & \\phantom{-}2\n",
    "\\end{pmatrix}$\n",
    "\n",
    " $~$ \n",
    "\n",
    "* Determine whether the given matrix is singular or nonsingular. $~$If it is nonsingular, find the inverse using $\\mathbf{A}^{-1}=\\frac{\\mathrm{adj}\\,\\mathbf{A}}{\\mathrm{det}\\,\\mathbf{A}}$\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 3&  0& \\phantom{-}0\\\\ \n",
    " 0&  6& \\phantom{-}0\\\\ \n",
    " 0&  0& -2 \n",
    "\\end{pmatrix}, \\;\\;\\;\n",
    "\\begin{pmatrix}\n",
    " 0 & -1 & \\phantom{-}1 & 4\\\\ \n",
    " 3 & \\phantom{-}2 & -2 & 1\\\\ \n",
    " 0 & \\phantom{-}4 & \\phantom{-}0 & 1\\\\ \n",
    " 1 & \\phantom{-}0 & -1 & 1 \n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Find the inverse of the given matrix or show that no inverse exists\n",
    "  $\\begin{pmatrix}\n",
    " 1 & 2 & 3\\\\ \n",
    " 4 & 5 & 6\\\\ \n",
    " 7 & 8 & 9 \n",
    "\\end{pmatrix},\\;\\;\n",
    "\\begin{pmatrix}\n",
    " \\phantom{-}4 & \\phantom{-}2 & 3 \\\\ \n",
    " \\phantom{-}2 & \\phantom{-}1 & 0\\\\ \n",
    " -1 & -2 & 0\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* If $\\mathbf{A}$ is nonsingular, then $\\left( \\mathbf{A}^T\\right)^{-1}=\\left( \\mathbf{A}^{-1}\\right)^T$, $~$verify this for\n",
    "  $\\mathbf{A}=\\begin{pmatrix}\n",
    " 1 & 4\\\\ \n",
    " 2 & 10 \n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Find the inverse of the rotation matrix \n",
    "\n",
    "  $\\mathbf{M}=\\begin{pmatrix}\n",
    " \\cos\\theta & -\\sin\\theta\\\\ \n",
    " \\sin\\theta & \\phantom{-}\\cos\\theta \n",
    "\\end{pmatrix}$\n",
    "  \n",
    "  What does $\\mathbf{A}=\\mathbf{M}^{-1}\\mathbf{B}$ represents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* A nonsingular matrix $\\mathbf{A}$ is said to be **orthogonal** if $\\mathbf{A}^{-1}=\\mathbf{A}^T$ \n",
    "\n",
    "  (a) $~$Verify tha the rotation matrix is orthogonal\n",
    "  \n",
    "  (b) $~$Verify that $\\displaystyle\\mathbf{A}=\\frac{1}{\\sqrt{6}}\\begin{pmatrix}\n",
    " \\sqrt{2} & \\phantom{-}0 & -2 \\\\ \n",
    " \\sqrt{2} & \\phantom{-}\\sqrt{3} & \\phantom{-}1\\\\ \n",
    " \\sqrt{2} &  -\\sqrt{3} & \\phantom{-}1\n",
    "\\end{pmatrix}~$ is an orthogonal matrix\n",
    "\n",
    " $~$\n",
    " \n",
    "* Show that if $\\mathbf{A}$ is an orthogonal matrix, $~$then $\\mathrm{det}\\,\\mathbf{A}=\\pm 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Suppose $\\mathbf{A}$ and $\\mathbf{B}~$ are nonsingular $~n\\times n$ matrices. Then show that $\\mathbf{AB}~$ is nonsingular\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}$ and $\\mathbf{B}~$ are $~n\\times n$ matrices and that either $\\mathbf{A}$ or $\\mathbf{B}~$ is singular. $~$Then show that $\\mathbf{AB}~$ is singular\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}~$ is a nonsingular matrix. $~$Then show that $\\displaystyle\\mathrm{det}\\,\\mathbf{A}^{-1}=\\frac{1}{\\mathrm{det}\\,\\mathbf{A}}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}^2=\\mathbf{A}$. $~$Then show that either $\\mathbf{A}=\\mathbf{I}~$ or $~\\mathbf{A}~$ is singular \n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}$ and $\\mathbf{B}~$ are $~n\\times n$ matrices. $~\\mathbf{A}~$ is nonsingular, $~$and $\n",
    "\\mathbf{AB}=\\mathbf{0}$. $~$Then show that $\\mathbf{B}=\\mathbf{0}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}$ and $\\mathbf{B}~$ are $~n\\times n$ matrices. $~\\mathbf{A}~$ is nonsingular, $~$and $\n",
    "\\mathbf{AB}=\\mathbf{AC}$. $~$Then show that $\\mathbf{B}=\\mathbf{C}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Suppose $\\mathbf{A}$ and $\\mathbf{B}~$ are nonsingular $~n\\times n$ matrices. Is $~\\mathbf{A} +\\mathbf{B}~$ necessarily nonsingular?\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}~$ is a nonsingular matrix. $~$Then show that $\\mathbf{A}^T~$ is nonsingular\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}$ and $\\mathbf{B}~$ are $~n\\times n~$ nonzero matrices and $\\mathbf{AB}=\\mathbf{0}$. $~$Then show that both $\\mathbf{A}~$ and $~\\mathbf{B~}$ are singular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXrA8VLoAOsQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.7 Cramer's Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AD97odiMAOsR",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $\\mathrm{det}(\\mathbf{A}) \\neq 0$, $~$the solution of the system is given by\n",
    "\n",
    "  > $\\displaystyle x_k=\\frac{\\mathrm{det}(\\mathbf{A}_k)}{\\mathrm{det}(\\mathbf{A})}$, $~$$k=1, 2, \\cdots, n$\n",
    "  \n",
    "where\n",
    "\n",
    "  >$\\mathbf{A}_k=\n",
    "  \\begin{pmatrix}\n",
    "    a_{11} & \\cdots & a_{1k-1} & {\\color{red} {b_1}}    & a_{1k+1} & \\cdots & a_{1n}\\\\ \n",
    "    a_{21} & \\cdots & a_{2k-1} & {\\color{red} {b_2}}    & a_{2k+1} & \\cdots & a_{2n} \\\\ \n",
    "    \\vdots &        & \\vdots   & {\\color{red} {\\vdots}} & \\vdots   &        & \\vdots\\\\ \n",
    "    a_{n1} & \\cdots & a_{nk-1} & {\\color{red} {b_n}}    & a_{nk+1} & \\cdots & a_{nn}\n",
    "  \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgdFSUurAOsR",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.7\n",
    "\n",
    "* Solve the given system of equations by Cramer's rule\n",
    "\n",
    "  $\\begin{align*}\n",
    " -3x_1 + x_2 &= 3 \\\\ \n",
    " 2x_1 -4x_2 &= -6 \\\\ \\\\\n",
    " 0.1x_1 -0.4x_2 &= 0.13 \\\\ \n",
    " x_1 -x_2 &= 0.4 \\\\ \\\\\n",
    " 2x + y &=1\\\\\n",
    " 3x +2y &=-2\n",
    "\\end{align*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Consider the system\n",
    "\n",
    "  $$\\begin{align*}\n",
    " x_1 + x_2 &= 1 \\\\ \n",
    " x_1 +\\epsilon x_2 &= 2 \n",
    "\\end{align*}$$\n",
    "\n",
    "  When $\\epsilon$ is close to $1$, $~$the lines that make up the system are almost parallel\n",
    "  \n",
    "  (a) $~$Use Cramer's rule to show that a solution of the system is\n",
    "  \n",
    "  >$\\displaystyle x_1 = 1 -\\frac{1}{\\epsilon -1}, \\;\\;x_2 = \\frac{1}{\\epsilon - 1}$\n",
    "  \n",
    "  (b) $~$The system is said to be ill-conditioned since small changes in the input data(for example, the coefficients) causes a significant or large change in the output or solution. $~$Verify this by finding the solution of the system for $\\epsilon=1.01$ and then for $\\epsilon=0.99$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3amBwHFAOsS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.8 The Eigenvalue Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let $\\mathbf{A}$ be an $n \\times n~$ matrix. $~$A number $\\lambda$ is said to be an **eigenvalue** of \n",
    "  $\\mathbf{A}$ if there exists a nonzero solution vector $\\mathbf{k}$ of the linear system\n",
    "\n",
    "  >$\\mathbf{A}\\mathbf{k}=\\lambda\\mathbf{k}$\n",
    "\n",
    "  and the solution vector $\\mathbf{k}$ is said to be an **eigenvector** corresponding to the eigenvalue $\\lambda$\n",
    "  \n",
    "* The problem of solving $~\\mathbf{A}\\mathbf{k}=\\lambda\\mathbf{k}~$ for nonzero vectors $\\mathbf{k}$ is\n",
    "  called to be the **eigenvalue problem** for $\\mathbf{A}$\n",
    "  \n",
    "* We must solve the **characteristic equation** \n",
    "  $~\\mathrm{det}(\\mathbf{A} -\\lambda\\mathbf{I})=0~$ to find an eigenvalue $\\lambda$\n",
    "  \n",
    "* To find an eigenvector $\\mathbf{k}$ corresponding to an eigenvalue $\\lambda$, $~$we solve \n",
    "  $~(\\mathbf{A} -\\lambda\\mathbf{I})\\mathbf{k}=\\mathbf{0}~$ by applying Gauss elimination \n",
    "  to $~(\\mathbf{A} -\\lambda\\mathbf{I}|\\mathbf{0})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Find the eigenvalues and eigenvectors of\n",
    " \n",
    "  >$\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    1 & 2 &  1\\\\ \n",
    "    6 &-1 &  0\\\\ \n",
    "   -1 &-2 & -1\n",
    "  \\end{array}\\right)   \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  To find the eigenvalues, $~$we solve\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\mathrm{det} (\\mathbf{A} -\\lambda\\mathbf{I}) =\n",
    "  \\begin{vmatrix}\n",
    "    1 -\\lambda & \\;\\;\\,2 & \\;\\;\\,1\\\\ \n",
    "    6 & -1 -\\lambda & \\;\\;\\,0\\\\ \n",
    "    -1\\;\\;\\, & -2 & -1 -\\lambda\n",
    "  \\end{vmatrix}=0}  \n",
    "  $\n",
    "  \n",
    "  It follows that the characteristic equation is $~-\\lambda^3 -\\lambda^2 +12\\lambda=-\\lambda(\\lambda+4)(\\lambda-3)=0$\n",
    "  \n",
    "  Hence the eigenvalues are $~\\lambda_1=-4$, $\\lambda_2=0$, $\\lambda_3=3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  For $\\lambda_1=-4$, $~$we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} +4\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    5 & 2 &  1 & 0\\\\ \n",
    "    6 & 3 &  0 & 0\\\\ \n",
    "   -1 &-2 &  3 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 1 & 0\\\\ \n",
    "    0 & 1 &-2 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-k_3$, $\\text{ }k_2=2k_3$. Choosing $\\text{ }k_3=1$ gives the eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    -1\\\\ \n",
    "     2\\\\ \n",
    "     1\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  For $\\lambda_2=0$, $\\text{ }$we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} -0\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 2 &  1 & 0\\\\ \n",
    "    6 &-1 &  0 & 0\\\\ \n",
    "   -1 &-2 & -1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & \\frac{1}{13} & 0\\\\ \n",
    "    0 & 1 & \\frac{6}{13} & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-\\frac{1}{13}k_3$, $\\text{ }k_2=-\\frac{6}{13}k_3$. $\\text{ }$Choosing $\\text{ }k_3=1$ gives the eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "    -\\frac{1}{13}\\\\ \n",
    "    -\\frac{6}{13}\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1WHm8niDAOsT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  For $\\lambda_3=3$, $\\text{ }$we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} -3\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "   -2 & 2 &  1 & 0\\\\ \n",
    "    6 &-4 &  0 & 0\\\\ \n",
    "   -1 &-2 & -4 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & 1 & 0\\\\ \n",
    "    0 & 1 & \\frac{3}{2} & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=-k_3$, $\\text{ }k_2=-\\frac{3}{2}k_3$. $\\text{ }$Choosing $\\text{ }k_3=1$ gives the eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -1\\\\ \n",
    "   -\\frac{3}{2}\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF_02tP1AOsT",
    "outputId": "a4adb1d5-e472-4d99-a8db-a41f02471ea7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A = sympy.Matrix([[1, 2, 1], [6, -1, 0], [-1, -2, -1]])\n",
    "A.eigenvects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Find the eigenvalues and eigenvectors of \n",
    "   >$\\mathbf{A}=\n",
    "   \\left(\\begin{array}{rr}\n",
    "     3 & 4 \\\\ \n",
    "    -1 & 7 \n",
    "   \\end{array}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   From the characteristic equation\n",
    "   \n",
    "   >$\n",
    "   \\mathrm{det}(\\mathbf{A} -\\lambda\\mathbf{I})=\n",
    "   \\left|\\begin{array}{cc}\n",
    "     3-\\lambda & 4 \\\\ \n",
    "    -1 & 7 -\\lambda \n",
    "   \\end{array}\\right|\n",
    "   =(\\lambda -5)^2=0\n",
    "   $,\n",
    "   \n",
    "   we see $\\lambda_1=\\lambda_2=5~$ is an eigenvalue of algebraic multiplicity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  To find\n",
    "   the eigenvector(s) corresponding to $\\lambda_1=5$, $\\text{ }$we resort to \n",
    "   the system $(\\mathbf{A} -5\\mathbf{I}|\\mathbf{0})$\n",
    "   \n",
    "  >$\n",
    "  (\\mathbf{A} -5\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "   -2 & 4 & 0\\\\ \n",
    "   -1 & 2 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 &-2 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=2k_2$. $\\text{ }$If we choose $k_2=1$, $~$we find the single eigenvector \n",
    "  \n",
    "  >$\\mathbf{k}_1=\\begin{pmatrix}\n",
    "     2 \\\\ 1\n",
    "   \\end{pmatrix}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLqzpeH6AOsX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  We define the geometric multiplicity of an eigenvalue\n",
    "  to be the number of linearly independent eigenvectors for the eigenvalue.\n",
    "  $~$When the geometric multiplicity of an eigenvalue is less than the algebraic \n",
    "  multiplicity, $\\text{ }$we say the matrix is *defective*. $\\text{ }$In the case of defective matrices,\n",
    "  $~$we must search for additional system \n",
    "\n",
    "  >$\n",
    "  (\\mathbf{A} -5\\mathbf{I}|\\mathbf{k}_1) =\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "   -2 & 4 & 2\\\\ \n",
    "   -1 & 2 & 1\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rr|r}\n",
    "    1 &-2 & -1\\\\ \\hdashline\n",
    "    0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1-2k_2=-1$. $\\text{ }$If we choose $k_2=0$, $~$we find the generalized eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_2=\\begin{pmatrix}\n",
    "     -1 \\\\ \\;\\;0\n",
    "   \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CdNxcPIAOsY",
    "outputId": "161aa32f-c1e8-484c-c3b6-22dcbff3a73e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A = sympy.Matrix([[3, 4], [-1, 7]])\n",
    "A.eigenvects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Find the eigenvalues and eigenvectors of\n",
    " \n",
    "  >$\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    9 & 1 & 1\\\\ \n",
    "    1 & 9 & 1\\\\ \n",
    "    1 & 1 & 9\n",
    "  \\end{array}\\right)   \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  The characteristic equation\n",
    "  \n",
    "  >$\n",
    "  \\mathrm{det} (\\mathbf{A} -\\lambda\\mathbf{I}) =\n",
    "  \\begin{vmatrix}\n",
    "    9 -\\lambda & 1 & 1\\\\ \n",
    "    1 & 9 -\\lambda & 1\\\\ \n",
    "    1 & 1 & 9 -\\lambda\n",
    "  \\end{vmatrix}=-(\\lambda-11)(\\lambda-8)^2=0  \n",
    "  $\n",
    "  \n",
    "  shows that $\\lambda_1=11$ and that $\\lambda_2=\\lambda_3=8$ is an eigenvalue of multiplicity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  For $\\lambda_1=11$, $~$we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} -11\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "   -2 & 1 &  1 & 0\\\\ \n",
    "    1 &-2 &  1 & 0\\\\ \n",
    "    1 & 1 & -2 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 0 & -1 & 0\\\\ \n",
    "    0 & 1 & -1 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Thus $k_1=k_3$, $k_2=k_3$. $~$Choosing $k_3=1$ gives the eigenvector\n",
    "  \n",
    "  >$\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  For $\\lambda_2=8$, $~$we have\n",
    "  \n",
    "  >$\n",
    "  (\\mathbf{A} -8\\mathbf{I}|\\mathbf{0}) =\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 1 &  1 & 0\\\\ \n",
    "    1 & 1 &  1 & 0\\\\ \n",
    "    1 & 1 &  1 & 0\n",
    "  \\end{array}\\right)\n",
    "  \\overset{\\text{row operations}}{\\Longrightarrow}\n",
    "  \\left(\\begin{array}{rrr|r}\n",
    "    1 & 1 & 1 & 0\\\\ \\hdashline\n",
    "    0 & 0 & 0 & 0\\\\ \n",
    "    0 & 0 & 0 & 0\n",
    "  \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Here $k_1 +k_2 +k_3=0$, $~$we are free to select two of the variables arbitrarily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-PBMpKLAOsc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "  Choosing, $~$on the one hand, $~k_2=1$, $k_3=0$, and on the other, $~k_2=0$, $k_3=1$, $~$we obtain\n",
    "  two linearly independent eigenvectors\n",
    "  \n",
    "  >$\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -1\\\\ \n",
    "    1\\\\ \n",
    "    0\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -1\\\\ \n",
    "    0\\\\ \n",
    "    1\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  corresponding to a single eigenvalue. $~$If instead we choose $k_2=1$, $k_3=1$ and then $k_2=1$, $k_3=-1$, $~$we obtain, respectively, two entirely different but orthogonal eigenvectors\n",
    "  \n",
    "  >$\\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -2\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\\\ \n",
    "    1\\\\ \n",
    "   -1\n",
    "  \\end{array}\\right)\n",
    "  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvUzJZggAOsd",
    "outputId": "dba4b1c2-c869-4bb8-a984-375b81d9a4df",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A = sympy.Matrix([[9, 1, 1], [1, 9, 1], [1, 1, 9]])\n",
    "A.eigenvects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNaLuae8AOsh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let $\\mathbf{A}$ be a square matrix with real entries. If $\\lambda=\\alpha +i\\beta$, $~\\beta \\neq 0$,\n",
    "  $~$is a complex eigenvalue of $\\mathbf{A}$,\n",
    "  \n",
    "  >$\\mathbf{A}\\mathbf{\\bar{k}}=\\bar{\\lambda}\\mathbf{\\bar{k}}$\n",
    "  \n",
    "* $\\lambda=0~$ is an eigenvalue of $~\\mathbf{A}$ if and only if $~\\mathbf{A}$ is singular\n",
    "\n",
    "* If $~\\lambda~$ is an eigenvalue of nonsingular $~\\mathbf{A}$ with eigenvector $~\\mathbf{k}$,\n",
    "  $~1/\\lambda$ is an eigenvalue of $~\\mathbf{A}^{-1}$ with the same eigenvector $~\\mathbf{k}$\n",
    "  \n",
    "* The eigenvalues of an upper triangular, $~$lower triangular, $~$and diagonal matrix are the main diagonal entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxmN7VbPAOsi",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.8\n",
    "\n",
    "* Find the eigenvalues and eigenvectors of the given matrix. $~$State whether the matrix is singular or nonsingular\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " -1& 2\\\\ \n",
    " -7& 8\n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\begin{pmatrix}\n",
    " 4 & \\phantom{-}8 \\\\ \n",
    " 0 & -5 \n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\begin{pmatrix}\n",
    " 0 & 0 & -1 \\\\ \n",
    " 1 & 0 & \\phantom{-}0 \\\\ \n",
    " 1 & 1 & -1 \n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Find the eigenvalues and eigenvectors of the given nonsingular matrix $\\mathbf{A}$. $~$Then without finding $\\mathbf{A}^{-1}$, $~$find its eigenvalues and corresponding eigenvectors\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 5& 1\\\\ \n",
    " 1& 5\n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\begin{pmatrix}\n",
    " 4 & 2 & -1 \\\\ \n",
    " 0 & 3 & -2 \\\\ \n",
    " 0 & 0 & \\phantom{-}5 \n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* True or False: $~$If $\\lambda$ is an eigenvalue of an $n \\times n~$ matrix $\\mathbf{A}$, $~$then the matrix $\\mathbf{A}-\\lambda\\mathbf{I}~$ is singular. Justify your answer\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\lambda$ is an eigenvalue with corresponding eigenvector $~\\mathbf{k}~$ of an $n\\times n~$ matrix $\\mathbf{A}$.\n",
    "  \n",
    "  (a) $~$If $\\mathbf{A}^2=\\mathbf{AA}$, $~$then show that $\\mathbf{A}^2\\mathbf{k}=\\lambda^2\\mathbf{k}$. $~$Explain the meaning of the last equation\n",
    "  \n",
    "  (b) $~$Verify the result obtained in part (a) for the matrix $\\mathbf{A}=\\begin{pmatrix}\n",
    " 2 & 3\\\\ \n",
    " 5 & 4\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  (c) $~$Generalize the result in part (a)\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Let $\\mathbf{A}$ and $\\mathbf{B}$ be $n \\times n~$ matrices. The matrix $\\mathbf{B}$ is said to be **similar** to the matrix $\\mathbf{A}~$ if there exists a nonsingular matrix $\\mathbf{S}$ such that $\\mathbf{B}=\\mathbf{S}^{-1}\\mathbf{AS}$. $~$If $\\mathbf{B}$ is similar to $\\mathbf{A}$, $~$then show that $\\mathbf{A}$ is similar to $\\mathbf{B}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}$ and $\\mathbf{B}$ are similar matrices. Show that $\\mathbf{A}$ and $\\mathbf{B}$ have the same eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmzDgpKjAOsk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.9 Powers of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qg4_a_fzAOsl",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Cayley-Hamilton Theorem**\n",
    "\n",
    "  If $(-1)^n \\lambda^n +c_{n-1}\\lambda^{n-1} + \\cdots +c_1 \\lambda +c_0 = 0$ is the characteristic equation\n",
    "  of $n \\times n$ matrix $\\mathbf{A}$, $~$then\n",
    "  \n",
    "  $$(-1)^n \\mathbf{A}^n +c_{n-1}\\mathbf{A}^{n-1} + \\cdots +c_1 \\mathbf{A} +c_0 \\mathbf{I} = \\mathbf{0}$$\n",
    "  \n",
    "  And we can write\n",
    "  \n",
    "  $$\\mathbf{A}^m = a_0 \\mathbf{I} +a_1 \\mathbf{A} +\\cdots +a_{n-1}\\mathbf{A}^{n-1}$$\n",
    "    \n",
    "  and the equation for the eigenvalues\n",
    "    \n",
    "  $$\\lambda^m = a_0 +a_1 \\lambda +\\cdots +a_{n-1}\\lambda^{n-1}$$\n",
    "    \n",
    "  hold for the same constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGtFWkTwAOsn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.9\n",
    "\n",
    "* Verify that the given matrix satisfies its own characteristic equation\n",
    "  $~\\mathbf{A}=\\begin{pmatrix}\n",
    " 1 & -2\\\\ \n",
    " 4 & \\phantom{-}5\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Compute $\\mathbf{A}^m$\n",
    "\n",
    "  $\\mathbf{A}=\\begin{pmatrix}\n",
    " 8 & 5\\\\ \n",
    " 4 & 0\n",
    "\\end{pmatrix}; \\;\\;m=5,\\;\\;\n",
    "\\mathbf{A}=\\begin{pmatrix}\n",
    " 1 & 1 & 1\\\\ \n",
    " 0 & 1 & 2\\\\ \n",
    " 0 & 1 & 0\n",
    "\\end{pmatrix}; \\;\\;m=10$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Show that the given matrix has an eigenvalue $\\lambda_1$ of multiplicity two. $~$As a consequence, $~$the equation $\\lambda^m=c_0+c_1\\lambda$ does not yield enough independent equations to form a system for determining the coefficients $c_i$. $~$Use the derivative (with respect to $\\lambda$) of this equation evaluated at $\\lambda_1$ as the extra needed equation to form a system. $~$Compute $\\mathbf{A}^m$ and use this result to compute the indicated power of the matrix $\\mathbf{A}$\n",
    "\n",
    "  $\\mathbf{A}=\\begin{pmatrix}\n",
    " \\phantom{-}7 & 3\\\\ \n",
    " -3 & 1\n",
    "\\end{pmatrix}; \\;\\;m=6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Show that $\\lambda=0~$ is an eigenvalue of each matrix. $~$In this case, $~$the coefficient $c_0$ in the characteristic equation\n",
    "\n",
    "  >$(-1)^n\\mathbf{A}^n + c_{n-1}\\mathbf{A}^{n-1}+\\cdots+c_1\\mathbf{A}+c_0\\mathbf{I}=\\mathbf{0}$\n",
    "  \n",
    "  is $0$. $~$Compute $\\mathbf{A}^m$ in each case. $~$In part (a), $~$explain why we do not have to solve any system for the coefficients $c_1$ in determining $\\mathbf{A}^m$\n",
    "  \n",
    "  $(a)\\;\\;\\mathbf{A}=\\begin{pmatrix}\n",
    " 1 & 1\\\\ \n",
    " 3 & 3\n",
    "\\end{pmatrix},\\;\\;(b)\\;\\;\n",
    "\\mathbf{A}=\\begin{pmatrix}\n",
    " 2 & 1 & \\phantom{-}1\\\\ \n",
    " 1 & 0 & -2\\\\ \n",
    " 1 & 1 & \\phantom{-}3\n",
    "\\end{pmatrix}$\n",
    "  \n",
    "  $~$\n",
    "\n",
    "* A non-zero $n \\times n$ matrix $\\mathbf{A}~$ is said to be **nilpotent of index $m$** $~$if $m$ is the smallest positive integer for which $\\mathbf{A}^m=\\mathbf{0}$. $~$(a) $~$Explain why any nilpotent matrix $~\\mathbf{A}$ is singular. $~$(b) $~$Show that all the eigenvalues of a nilpotent matrix $~\\mathbf{A}$ are $0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GuaRCgkAOsn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.10 Orthogonal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QtUyfBt3AOso",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* <font color='red'>Let $\\mathbf{A}$ be a *symmetric* matrix ($\\mathbf{A}=\\mathbf{A}^T$) with *real* entries. Then the eigenvalues of $\\mathbf{A}$ are *real*</font>\n",
    "\n",
    "* <font color='blue'>Let $\\mathbf{A}$ be a *symmetric* matrix. Then eigenvectors corresponding to distinct(different) eigenvalues are *orthogonal*</font>\n",
    "\n",
    "* <font color='red'>An $n \\times n$ matrix $\\mathbf{A}$ is *orthogonal* ($\\mathbf{A}^{-1}=\\mathbf{A}^T$) $~$if and only if its columns $\\mathbf{x}_1$, $\\mathbf{x}_2$, $\\cdots$, $\\mathbf{x}_n$ form an orthonormal set</font>\n",
    "  \n",
    "  >$\\mathbf{x}_i \\cdot \\mathbf{x}_j=0$, $i \\neq j\\text{ }$ and $\\text{ }\\mathbf{x}_i \\cdot \\mathbf{x}_i=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiQD3oV_AOsp",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "* It may not be possible to find $n$ linearly independent eigenvectors for an $n \\times n$ matrix $\\mathbf{A}$\n",
    "  when some of eigenvalues are repeated (defective matrix). \n",
    "  \n",
    "* <font color='red'>But a symmetric matrix is an exception. $~$It can be proved that a set of \n",
    "  $n$ linearly independent eigenvectors can always be found for an $n \\times n$ symmetric matrix $\\mathbf{A}$ even\n",
    "  there is some repetition of the eigenvalues</font>\n",
    "  \n",
    "* However, $~$this does not mean that all eigenvectors are mutually orthogonal for an $n \\times n$ symmetric matrix $\\mathbf{A}$.\n",
    "  The set of eigenvectors corresponding to distinct eigenvalues are orthogonal; $~$but different eigenvectors corresponding to \n",
    "  a repeated eigenvalue may not be orthogonal\n",
    "  \n",
    "* But it is always possible to *find* or *construct* a set of $n$ mutually orthogonal eigenvectors by using Gram-Schmidt orthogonalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4TbvYHHAOsp",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Construct an orthogonal matrix from the eigenvectors of\n",
    "\n",
    "> $\n",
    "  \\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    7 & 4 & -4\\\\ \n",
    "    4 &-8 & -1\\\\ \n",
    "   -4 &-1 & -8\n",
    "  \\end{array}\\right)   \n",
    "  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A = sympy.Matrix([[7, 4, -4], [4, -8, -1], [-4, -1, -8]])\n",
    "A.eigenvects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v1 = A.eigenvects()[1][2][0].T\n",
    "v2 = A.eigenvects()[0][2][0].T\n",
    "v3 = A.eigenvects()[0][2][1].T\n",
    "\n",
    "B = sympy.Matrix(sympy.GramSchmidt([v1, v2, v3], True)); B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "B.T * B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrEmN07pAOsq",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.10\n",
    "\n",
    "* (a) $~$Verify that the indicated column vectors are eigenvectors of the given matrix, $~$(b)$~$identify the corresponding eigenvalues, and $~$(c)$~$verify that the column vectors are orthogonal\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 3 & 2 & 2\\\\ \n",
    " 2 & 2 & 0\\\\ \n",
    " 2 & 0 & 4\n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\begin{pmatrix}\n",
    "-2\\\\ \n",
    "\\phantom{-}2\\\\ \n",
    "\\phantom{-}1\n",
    "\\end{pmatrix}, \\;\n",
    "\\begin{pmatrix}\n",
    "\\phantom{-}1\\\\ \n",
    "\\phantom{-}2\\\\ \n",
    "-2\n",
    "\\end{pmatrix}, \\;\n",
    "\\begin{pmatrix}\n",
    "2\\\\ \n",
    "1\\\\ \n",
    "2\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Determine whether the given matrix is orthogonal\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 0 & 1 & 0\\\\ \n",
    " 1 & 0 & 0\\\\ \n",
    " 0 & 0 & 1\n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\begin{pmatrix}\n",
    " \\phantom{-}0 & 0 & 1\\\\ \n",
    " -\\frac{12}{13}& \\frac{5}{13} & 0\\\\ \n",
    " \\phantom{-}\\frac{5}{13}&  \\frac{12}{13}& 0\n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Construct an orthogonal matrix from the eigenvectors of the given symmetric matrix (The answers are not unique)\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 1 & 9 \\\\ \n",
    " 9 & 1\n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\begin{pmatrix}\n",
    " -8 & 5 & 4\\\\ \n",
    " \\phantom{-} 5 & 3 & 1\\\\ \n",
    " \\phantom{-} 4 & 1 & 0\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* (a)$~$Verify that the indicated column vectors are eigenvectors of the given symmetric matrix and $~$(b)$~$ identify the corresponding eigenvalues. $~$(c)$~$Use Gram-Schmidt process to construct an orthogonal matrix $\\mathbf{P}$ from the eigenvectors\n",
    "\n",
    "  $\\mathbf{A}=\n",
    "\\begin{pmatrix}\n",
    " 0 & 2 & 2\\\\ \n",
    " 2 & 0 & 2\\\\ \n",
    " 2 & 2 & 0\n",
    "\\end{pmatrix}; \\;\\; \\mathbf{k}_1=\\begin{pmatrix}\n",
    "\\phantom{-}1\\\\ -1\\\\ \\phantom{-}0\n",
    "\\end{pmatrix}, \\;\\; \\mathbf{k}_2=\\begin{pmatrix}\n",
    "\\phantom{-}1\\\\ \\phantom{-}0\\\\ -1\n",
    "\\end{pmatrix}, \\;\\; \\mathbf{k}_3 = \\begin{pmatrix}\n",
    "1 \\\\ 1 \\\\ 1\n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Suppose $\\mathbf{A}$ and $\\mathbf{B}~$ are $~n\\times n$ orthogonal matrices. Then show that $\\mathbf{AB}~$ is orthogonal\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}$ is an orthogonal matrix. $~$Is $\\mathbf{A}^2~$ is orthogonal\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}~$ is an orthogonal matrix. $~$Then show that $\\mathbf{A}^{-1}$ is orthogonal\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}~$ is an orthogonal matrix. $~$Then show that $\\mathrm{det}\\,\\mathbf{A}=\\pm 1$ \n",
    "\n",
    "  $~$\n",
    "\n",
    "* Suppose $\\mathbf{A}~$ is an orthogonal matrix such that $~\\mathbf{A}^2=\\mathbf{I}~$. $~$Then show that $\\mathbf{A}^T=\\mathbf{A}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Show that the rotation matrix is orthogonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TiCMylHAOsr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.11 Approximation of Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSL4LajSAOsr",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let $\\lambda_1$, $\\lambda_2$, $\\cdots$, $\\lambda_k$, $\\cdots$, $\\lambda_n$ denote the eigenvalues of an $n \\times n$ matrix $\\mathbf{A}$. The eigenvalue $\\lambda_k$ is said to be the **dominant eigenvalue** of $\\mathbf{A}$ if $|\\lambda_k| > |\\lambda_i|$, $~i=1,2,\\cdots,n$, $~$but $\\text{ }i \\neq k$\n",
    "\n",
    "* An eigenvector corresponding to $\\lambda_k$ is called the **dominant eigenvector** of $\\mathbf{A}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Power Method**\n",
    "\n",
    "  Let us assume that the eigenvalues of $\\mathbf{A}$ are such that\n",
    "  $|\\lambda_1| > |\\lambda_2| \\geq |\\lambda_3| \\geq \\cdots \\geq |\\lambda_n|$\n",
    "  and that the corresponding $n$ eigenvectors $\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$\n",
    "  are linearly independent. $~$Because of this last assumption, $~n$ eigenvectors\n",
    "  can serve as a basis for $\\mathbb{R}^n$. $~$For any nonzero $n \\times 1$ vector $\\mathbf{x}_0$, \n",
    "  \n",
    "  > $\\mathbf{x}_0 =c_1 \\mathbf{k}_1 +c_2 \\mathbf{k}_2 +c_3 \\mathbf{k}_3 +\\cdots +c_n \\mathbf{k}_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pb8NRJFuAOss",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  We shall also assume $\\mathbf{x}_0$ is chosen so that $c_1 \\neq 0$. $\\text{ }$We do the following procedure\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\begin{align*}\n",
    "     \\mathbf{A}\\mathbf{x}_0 &= c_1 \\mathbf{A}\\mathbf{k}_1 +c_2 \\mathbf{A}\\mathbf{k}_2 \n",
    "         +c_3 \\mathbf{A}\\mathbf{k}_3 +\\cdots +c_n \\mathbf{A}\\mathbf{k}_n\\\\ \n",
    "     &\\;\\big\\Downarrow \\;\\;\\mathbf{x}_i=\\mathbf{A}\\mathbf{x}_{i -1}, \\;\\mathbf{A}\\mathbf{k}_j=\\lambda_j \\mathbf{k}_j\\\\ \n",
    "     \\mathbf{x}_1 &= c_1 \\lambda_1\\mathbf{k}_1 +c_2 \\lambda_2\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3\\mathbf{k}_3 +\\cdots +c_n \\lambda_n\\mathbf{k}_n\\\\ \n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{A}\\mathbf{x}_1 &= c_1 \\lambda_1\\mathbf{A}\\mathbf{k}_1 +c_2 \\lambda_2\\mathbf{A}\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3\\mathbf{A}\\mathbf{k}_3 +\\cdots +c_n \\lambda_n\\mathbf{A}\\mathbf{k}_n\\\\ \n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{x}_2 &= c_1 \\lambda_1^2\\mathbf{k}_1 +c_2 \\lambda_2^2\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3^2\\mathbf{k}_3 +\\cdots +c_n \\lambda_n^2\\mathbf{k}_n\\\\\n",
    "     &\\Downarrow \\\\\n",
    "     \\mathbf{x}_m &= c_1 \\lambda_1^m\\mathbf{k}_1 +c_2 \\lambda_2^m\\mathbf{k}_2 \n",
    "         +c_3 \\lambda_3^m\\mathbf{k}_3 +\\cdots +c_n \\lambda_n^m\\mathbf{k}_n\\\\ \n",
    "     &= \\lambda_1^m \\left[c_1 \\mathbf{k}_1 +c_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^m\\mathbf{k}_2 \n",
    "         +c_3 \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^m\\mathbf{k}_3 +\\cdots +c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^m\\mathbf{k}_n \\right]\\\\        &\\;\\big\\Downarrow \\;\\;m \\rightarrow \\infty\\\\\n",
    "     \\mathbf{x}_m &\\simeq \\lambda_1^m c_1 \\mathbf{k}_1   \n",
    "  \\end{align*} } \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  Since a nonzero constant multiple of an eigenvalue is an eigenvector, $~$for large values of $m$ and under all the assumptions\n",
    "  that were made, $~$the $n \\times 1$ vector $\\mathbf{x}_m$ is an approximation to a dominant eigenvector associated with\n",
    "  the dominant eigenvalue $\\lambda_1$\n",
    "  \n",
    "  If $\\mathbf{x}_m$ is an approximation to a dominant eigenvector, $~$then the dominant eigenvalue $\\lambda_1$ can be approximated by\n",
    "  the **Rayleigh quotient**\n",
    "  \n",
    "  >$\\displaystyle\n",
    "   \\lambda_1=\\frac{\\mathbf{A}\\mathbf{x}_m \\cdot \\mathbf{x}_m}{\\mathbf{x}_m \\cdot \\mathbf{x}_m}\n",
    "  $\n",
    "  \n",
    "  Iteration often results in vectors whose entries become very large. $~$Large numbers can cause a problem in computation. One way around\n",
    "  this difficulty is to use a **scaled-down** normalized vector\n",
    "  \n",
    "  >$\\displaystyle\n",
    "  \\mathbf{x}_m \\leftarrow \n",
    "    \\frac{\\mathbf{x}_m}{\\left \\| \\mathbf{x}_m \\right \\|}\n",
    "  $\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxEEWQVvAOsu",
    "outputId": "e7d9a332-2844-441a-c9c1-4b8925c93828",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%run ./codes/ch08_code1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDnIIIxKAOsz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Method of Deflation**\n",
    "\n",
    "  After we have found the dominant eigenvalue $\\lambda_1$ of a matrix $\\mathbf{A}$, $~$it may still be necessary to find\n",
    "  nondominant eigenvalues. $~$We will limit the discussion to the case where $\\mathbf{A}$ is a *symmetric* matrix.\n",
    "  \n",
    "  Suppose $\\lambda_1$ and $\\mathbf{k}_1$ are, respectively, the dominant eigenvalue and a corresponding *normalized* eigenvector of\n",
    "  a symmetric matrix $\\mathbf{A}$. $~$Furthermore, $~$suppose the eigenvalues of $\\mathbf{A}$ are such that\n",
    "  \n",
    "  > $|\\lambda_1| > |\\lambda_2| > |\\lambda_3| > \\cdots > |\\lambda_n|$\n",
    "  \n",
    "  In this case, the matrix\n",
    "  \n",
    "  > $\\mathbf{A}_1 =\\mathbf{A} -\\lambda_1\\mathbf{k}_1\\mathbf{k}_1^T$\n",
    "  \n",
    "  has eigenvalues $0$, $|\\lambda_2|$, $|\\lambda_3|$, $\\cdots$, $|\\lambda_n|$ and that eigenvectors of $\\mathbf{A}_1$ are also eigenvectors \n",
    "  of $\\mathbf{A}$. $~$Note that $\\lambda_2$ is now the dominant eigenvalue of $\\mathbf{A}_1$.\n",
    " \n",
    " \n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSI9WSMsAOsz",
    "outputId": "81386a4d-acd6-4336-efd2-1fb0b4b66273",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%run ./codes/ch08_code2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIV5IV--AOs2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Inverse Power Method**\n",
    "\n",
    "  If we want to find the smallest eigenvalue instead of the largest one, then we perform power\n",
    "  iteration for $\\mathbf{A}^{1}$ (since the eigenvalues of $\\mathbf{A}^{-1}$ are the reciprocals of the eigenvalues of\n",
    "  $\\mathbf{A}$). Of course, $~$we do not want to compute $\\mathbf{A}^{-1}$\n",
    "\n",
    " \n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FObTb70qAOs3",
    "outputId": "9318ad33-0e45-4ff0-aa9e-ebc062c5f481",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%run ./codes/ch08_code3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoMSrGZ-AOs6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.12 Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwnLMJNZAOs7",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<font color='red'>For an $n \\times n$ matrix $\\mathbf{A}$, $~$can we find an $n \\times n\\,$ nonsingular matrix $\\mathbf{P}$ such that \n",
    "$\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{D}$ is a diagonal matrix?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cu3gprU9AOs8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* An $n \\times n$ matrix $\\mathbf{A}$ is diagonalizable if and only if $\\mathbf{A}$ has $n$ linearly independent eigenvectors\n",
    "\n",
    "  Let $\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$ be linearly independent eigenvectors corresponding to \n",
    "  eigenvalues $\\lambda_1$, $\\lambda_2$, $\\cdots$, $\\lambda_n$. $~$Next form the matrix $~\\mathbf{P}~$ with column vectors\n",
    "  $~\\mathbf{k}_1$, $\\mathbf{k}_2$, $\\cdots$, $\\mathbf{k}_n$\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{P}= \\begin{pmatrix}\n",
    "    \\mathbf{k}_1 & \\mathbf{k}_2 & \\cdots & \\mathbf{k}_n\n",
    "  \\end{pmatrix}\n",
    "  $\n",
    "  \n",
    "  We can wrtie the product $\\mathbf{A}\\mathbf{P}$ as\n",
    "  \n",
    "  >$\n",
    "  \\begin{align*}\n",
    "   \\mathbf{A}\\mathbf{P}\n",
    "      &= \n",
    "      \\begin{pmatrix}\n",
    "        \\mathbf{A}\\mathbf{k}_1 & \\mathbf{A}\\mathbf{k}_2 & \\cdots & \\mathbf{A}\\mathbf{k}_n \n",
    "      \\end{pmatrix} =\n",
    "      \\begin{pmatrix}\n",
    "        \\lambda_1\\mathbf{k}_1 & \\lambda_2\\mathbf{k}_2 & \\cdots & \\lambda_n\\mathbf{k}_n \n",
    "      \\end{pmatrix} \\\\\n",
    "      &=\\begin{pmatrix}\n",
    "           \\mathbf{k}_1 & \\mathbf{k}_2 & \\cdots & \\mathbf{k}_n\n",
    "        \\end{pmatrix}\n",
    "        \\begin{pmatrix}\n",
    "           \\lambda_1 &  &  & \\\\ \n",
    "                     & \\lambda_2 &  & \\\\ \n",
    "                     &  & \\ddots & \\\\ \n",
    "                     &  &  & \\lambda_n\n",
    "        \\end{pmatrix}=\\mathbf{P}\\mathbf{D}\n",
    "  \\end{align*}  \n",
    "  $\n",
    "  \n",
    "  Multiplying the last equation on the left by $\\mathbf{P}^{-1}$ then gives $\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "><img src=\"figures/ch08_figure04.png\" width=\"500\">\n",
    "\n",
    "* If an $n \\times n$ matrix $\\mathbf{A}$ has $n$ distinct eigenvalues, $~$it is diagonalizable\n",
    "* An $n \\times n$ matrix $\\mathbf{A}$ can be *orthogonally* diagonalized if and only if $\\mathbf{A}$ is symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:** $\\text{ }$ Diagonalize\n",
    "\n",
    "  >$\\mathbf{A}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    9 & 1 & 1\\\\ \n",
    "    1 & 9 & 1\\\\ \n",
    "    1 & 1 & 9\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  The eigenvalues and corresponding orthogonal eigenvectors are\n",
    "  \n",
    "  >$\\lambda_1=11$, $\\lambda_2=\\lambda_3=8$\n",
    "  \n",
    "  >$\\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    1\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right),  \n",
    "  \\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "   -2\\\\ \n",
    "    1\\\\ \n",
    "    1\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\\\ \n",
    "    1\\\\ \n",
    "   -1\n",
    "  \\end{array}\\right)\n",
    "  $  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  Multiplying these vectors, in turn, by the reciprocals of the norms $\\left \\| \\mathbf{k}_1 \\right \\|=\\sqrt{3}$,\n",
    "  $\\text{ }\\left \\| \\mathbf{k}_2 \\right \\|=\\sqrt{6}\\text{ }$ and $\\text{ }\\left \\| \\mathbf{k}_3 \\right \\|=\\sqrt{2}$,\n",
    "  $~$we obtain an orthonormal set\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{k}_1=\n",
    "  \\left(\\begin{array}{r}\n",
    "    \\frac{1}{\\sqrt{3}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}}\n",
    "  \\end{array}\\right),  \n",
    "  \\mathbf{k}_2=\n",
    "  \\left(\\begin{array}{r}\n",
    "    -\\frac{2}{\\sqrt{6}}\\\\ \n",
    "     \\frac{1}{\\sqrt{6}}\\\\ \n",
    "     \\frac{1}{\\sqrt{6}}\n",
    "  \\end{array}\\right) \\text{ and } \n",
    "  \\mathbf{k}_3=\n",
    "  \\left(\\begin{array}{r}\n",
    "    0\\;\\\\ \n",
    "    \\frac{1}{\\sqrt{2}}\\\\ \n",
    "   -\\frac{1}{\\sqrt{2}}\n",
    "  \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  We then use these vectors as columns to construct an orthogonal matrix that diagonalizes $\\mathbf{A}$\n",
    "  \n",
    "  >$\\mathbf{P}=\n",
    "  \\left(\\begin{array}{rrr}\n",
    "    \\frac{1}{\\sqrt{3}} & -\\frac{2}{\\sqrt{6}} &  0\\;\\\\ \n",
    "    \\frac{1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{6}} &  \\frac{1}{\\sqrt{2}}\\\\ \n",
    "    \\frac{1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{6}} & -\\frac{1}{\\sqrt{2}}\n",
    "  \\end{array}\\right)  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-J-8RMmAOs9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  This transforms $\\mathbf{A}$ to $\\mathbf{D}$\n",
    "  \n",
    "  >$\\mathbf{P}^{-1}\\mathbf{A}\\mathbf{P}=\\mathbf{P}^{T}\\mathbf{A}\\mathbf{P}=\n",
    "   \\begin{pmatrix}\n",
    "    11 & 0 & 0\\\\ \n",
    "     0 & 8 & 0\\\\ \n",
    "     0 & 0 & 8\n",
    "   \\end{pmatrix}=\\mathbf{D}$\n",
    "   \n",
    "   The entries in $\\mathbf{D}$ are the eigenvalues of $\\mathbf{A}$ and the order in which these numbers \n",
    "   appear on the diagonal corresponds to the order in which the eigenvectors are used as columns \n",
    "   in the matrix $\\mathbf{P}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example - Quadratic Forms:** $\\text{ }$ Identify the conic section whose equation $\\,2x^2 +4xy -y^2 =1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sympy import plot_implicit, symbols, Eq\n",
    "x, y = symbols('x y')\n",
    "\n",
    "p1 = plot_implicit(Eq(2*x**2 + 4*x*y - y**2, 1), (x, -3, 3), (y, -3, 3), aspect_ratio=(1, 1), size=(7, 7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " We can write the given equation as\n",
    "  \n",
    "  >$\n",
    "  \\begin{pmatrix}\n",
    "    x & y\n",
    "  \\end{pmatrix}\n",
    "  \\left(\\begin{array}{rr}\n",
    "    2 & 2\\\\ \n",
    "    2 &-1 \n",
    "  \\end{array}\\right)\n",
    "  \\begin{pmatrix}\n",
    "    x \\\\ \n",
    "    y\n",
    "  \\end{pmatrix}\n",
    "  =1 \\;\\text{ or }\\; \\mathbf{x}^T\\mathbf{A}\\mathbf{x}=1\n",
    "  $\n",
    "  \n",
    "  The eigenvalues and corresponding eigenvectors of $\\mathbf{A}$ are found to be\n",
    "  \n",
    "  >$\\lambda_1=-2$, $\\text{ }\\lambda_2=3$, $\\text{ }\\mathbf{k}_1=\\left(\\begin{array}{r} 1\\\\ -2 \\end{array}\\right)$,\n",
    "  >$\\text{ }\\mathbf{k}_2=\\left(\\begin{array}{r} 2\\\\ 1 \\end{array}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  Observe that $\\mathbf{k}_1$ and $\\mathbf{k}_2$ are orthogonal. $\\text{ }$Moreover, \n",
    "  $\\text{ }\\left \\| \\mathbf{k}_1 \\right \\| =\\left \\| \\mathbf{k}_2 \\right \\| =\\sqrt{5}$, $~$and so the vectors\n",
    "  \n",
    "  >$\\mathbf{k}_1=\\left(\\begin{array}{r} \\frac{1}{\\sqrt{5}}\\\\ -\\frac{2}{\\sqrt{5}} \\end{array}\\right)\\text{ }$ $\\text{and}$\n",
    "  >$\\text{ }\\mathbf{k}_2=\\left(\\begin{array}{r} \\frac{2}{\\sqrt{5}}\\\\ \\frac{1}{\\sqrt{5}} \\end{array}\\right)$\n",
    "  \n",
    "  are orthogonal. $~$Hence, $~$the matrix\n",
    "  \n",
    "  >$\\mathbf{P}=\n",
    "     \\left(\\begin{array}{rr} \\frac{1}{\\sqrt{5}} & \\frac{2}{\\sqrt{5}}\\\\ \n",
    "    -\\frac{2}{\\sqrt{5}} & \\frac{1}{\\sqrt{5}}\n",
    "    \\end{array}\\right)\n",
    "  $\n",
    "  \n",
    "  is orthogonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5Ee39geAOs9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " If we define the change of variables $\\text{ }\\mathbf{x}=\\mathbf{P}\\mathbf{\\hat{x}}\\text{ }$ \n",
    "  where $\\mathbf{\\hat{x}}=\\begin{pmatrix} \\hat{x} \\\\ \\hat{y} \\end{pmatrix}$, $~$then the quadratic form can\n",
    "  be written\n",
    "  \n",
    "  >$\\mathbf{x}^T\\mathbf{A}\\mathbf{x}=\n",
    "   \\mathbf{\\hat{x}}^T\\mathbf{P}^T\\mathbf{A}\\mathbf{P}\\mathbf{\\hat{x}}\n",
    "   =\\mathbf{\\hat{x}}^T\\mathbf{D}\\mathbf{\\hat{x}}=\n",
    "   \\begin{pmatrix}\n",
    "     \\hat{x} & \\hat{y}\n",
    "   \\end{pmatrix}\n",
    "   \\left(\\begin{array}{rr}\n",
    "    -2 & 0\\\\ \n",
    "     0 & 3 \n",
    "   \\end{array}\\right)\n",
    "   \\begin{pmatrix}\n",
    "     \\hat{x} \\\\ \n",
    "     \\hat{y}\n",
    "   \\end{pmatrix}=1\\;\\;\\text{or}\\;\\; -2\\hat{x}^2 +3\\hat{y}^2 =1$\n",
    "  \n",
    "  This last equation is recognized as the standard form of a hyperbola\n",
    "  \n",
    "> <img src=\"figures/ch08_figure05.png?raw=1\" width=\"350\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "hat_x, hat_y = symbols('hat_x hat_y')\n",
    "\n",
    "p1 = plot_implicit(Eq(-hat_x**2 + 3*hat_y**2, 1), (hat_x, -3, 3), (hat_y, -3, 3), aspect_ratio=(1, 1), size=(7, 7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvC2gLNxAOs-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.12\n",
    "\n",
    "* Determine whether the given matrix $\\mathbf{A}$ is diagonalizable. $~$If so, find the matrix $\\mathbf{P}$ that diagonalizes $\\mathbf{A}$ and the disgonal matrix $\\mathbf{D}$ such that $\\mathbf{D}=\\mathbf{P}^{-1}\\mathbf{AP}$\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " -9 & 13\\\\ \n",
    " -2 & 6\n",
    "\\end{pmatrix}, \\;\\; \\begin{pmatrix}\n",
    " 1 & -1 & 1 \\\\ \n",
    " 0 & \\phantom{-}1 & 0\\\\ \n",
    " 1 &  -1&  1\n",
    "\\end{pmatrix}, \\;\\;\\begin{pmatrix}\n",
    " 1 & \\phantom{-}2 & 0\\\\ \n",
    " 2 & -1 & 0\\\\ \n",
    " 0 & \\phantom{-}0 & 1\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* The given matrix $\\mathbf{A}$ is symmetric. $~$Find an orthogonal matrix $\\mathbf{P}$ that diagonalizes $\\mathbf{A}$ and the diagonal matrix $\\mathbf{D }$ such that $\\mathbf{D}=\\mathbf{P}^T\\mathbf{AP}$\n",
    "\n",
    "  $\\begin{pmatrix}\n",
    " 1 & 1\\\\ \n",
    " 1 & 1\n",
    "\\end{pmatrix}, \\;\\; \\begin{pmatrix}\n",
    " 0 & 1 & 0 \\\\ \n",
    " 1 & 0 & 0\\\\ \n",
    " 0 & 0 &  1\n",
    "\\end{pmatrix}, \\;\\;\\begin{pmatrix}\n",
    " 1 & 0 & 7\\\\ \n",
    " 0 & 1 & 0\\\\ \n",
    " 7 & 0 & 1\n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Identify the given conic section\n",
    "\n",
    "  $5x^2 -2xy +5y^2 =24$\n",
    "  \n",
    "  $-3x^2 +8xy +3y^2 =20$\n",
    "  \n",
    "  $~$\n",
    "  \n",
    "* Find $3 \\times 3~$ symmetric matrix that has eigenvalues $~\\lambda_1=1$, $~\\lambda_2=3$, and $~\\lambda_3=5$ and corresponding eigenvectors\n",
    "\n",
    "  $\\mathbf{k}_1 = \\begin{pmatrix}\n",
    "  \\phantom{-}1 \\\\ -1 \\\\ 1\n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\mathbf{k}_2 = \\begin{pmatrix}\n",
    "  \\phantom{-}1 \\\\ \\phantom{-}0 \\\\ -1\n",
    "\\end{pmatrix}, \\;\\;\n",
    "\\mathbf{k}_3 = \\begin{pmatrix}\n",
    "  1 \\\\ 2 \\\\ 1\n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If $\\mathbf{A}$ is an $n\\times n~$ diagonalizable matrix, then $\\mathbf{D}=\\mathbf{P}^{-1}\\mathbf{AP}$, $~$where $\\mathbf{D}$ is a diagonal matrix. $~$Show that if $m$ is a positive integer,  then $\\mathbf{A}^m=\\mathbf{PD}^m\\mathbf{P}^{-1}$\n",
    "\n",
    "  $~$\n",
    "  \n",
    "* Find the indicated power of the given matrix\n",
    "\n",
    "  $\\begin{align*}\n",
    " \\mathbf{A} &= \\begin{pmatrix}\n",
    " 1 & 1\\\\ \n",
    " 2 & 0\n",
    "\\end{pmatrix},\\;\\;\\mathbf{A}^5\\\\ \n",
    " \\mathbf{A} &= \\begin{pmatrix}\n",
    " 6 & -10\\\\ \n",
    " 3 & -5\n",
    "\\end{pmatrix},\\;\\;\\mathbf{A}^{10}\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Suppose $\\mathbf{A}$ is a nonsingular diagonalizable matrix. Then show that $\\mathbf{A}^{-1}$ is diagonalizable\n",
    "\n",
    "  $~$\n",
    "  \n",
    "* Suppose $\\mathbf{A}$ is a diagonalizable matrix. $~$Is the matrix $\\mathbf{P}$ unique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4PwNhKbAOs_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.13 LU Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STpqZUlUAOtA",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Let $\\mathbf{A}$ be a square matrix. $~$An *LU factorization* refers to the factorization of $\\mathbf{A}$ into \n",
    "  two factors  a lower triangular matrix $\\mathbf{L}$ and an upper triangular matrix $\\mathbf{U}$:\n",
    "\n",
    "  >$\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "* Without a proper ordering or permutations in the matrix, $~$the factorization may fail to materialize. \n",
    "  $~$This is a procedural problem. $~$It can be removed by simply reordering the rows of $\\mathbf{A}$.\n",
    "  $~$It turns out that a proper permutation in rows (or columns) is sufficient for LU factorization. \n",
    "  $~$LU factorization with partial pivoting (LUP) refers often to LU factorization with row permutations only\n",
    "  \n",
    "  >$\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "  where $\\mathbf{P}$ is a permutation matrix, which, when left-multiplied to $\\mathbf{A}$, reorders the rows of $\\mathbf{A}$. \n",
    "  $~$It turns out that all square matrices can be factorized in this form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If $\\mathbf{A}$ is invertible, then it admits an LU factorization if and only if all its leading principal minors are nonzero. \n",
    "  $~$If $\\mathbf{A}$ is a singular matrix of rank $k$, $~$then it admits an LU factorization if the first $k$ leading principal minors are nonzero\n",
    "\n",
    "* LU decomposition is basically a modified form of Gaussian elimination. $~$We transform the matrix $\\mathbf{A}$ into \n",
    "  an upper triangular matrix $\\mathbf{U}$ by eliminating the entries below the main diagonal. \n",
    "  $~$The **Doolittle algorithm** does the column-by-column elimination, starting from the left, by multiplying $\\mathbf{A}$ to \n",
    "  the left with atomic lower triangular matrices. It results in a *unit* lower triangular matrix and an upper triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Doolittle Algorithm**\n",
    "\n",
    "* We define\n",
    "\n",
    "  >$\\mathbf{A}^{(0)}=\\mathbf{A}$\n",
    "  \n",
    "* We eliminate the matrix elements below the main diagonal in the $k$-th column of $\\mathbf{A}^{(k -1)}$ \n",
    "  by adding to the $i$-th row of this matrix the $k$-th row multiplied by\n",
    "  \n",
    "  >$\\displaystyle l_{i,k}=\\frac{a_{i,k}^{(k-1)}}{a_{k,k}^{(k-1)}}$ $\\text{ for } i=k+1, \\cdots, n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  This can be done by multiplying $\\mathbf{A}^{(k -1)}$ to the left with the lower triangular matrix\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\mathbf{L}_k=\n",
    "     \\begin{pmatrix}\n",
    "         1      & 0      &           & \\cdots &        & 0      \\\\ \n",
    "         0      & \\ddots & \\ddots    &        &        &        \\\\ \n",
    "                &        & 1         &        &        &        \\\\ \n",
    "        \\vdots  &        &-l_{k+1,k} &        &        & \\vdots \\\\ \n",
    "                &        & \\vdots    &        & \\ddots & 0      \\\\ \n",
    "         0      &        &-l_{n,k}   &        & 0      & 1\n",
    "     \\end{pmatrix}} \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* We set\n",
    "  \n",
    "  >$\\mathbf{A}^{(k)}=\\mathbf{L}_k\\mathbf{A}^{(k-1)}$, $k=1,\\cdots,n -1$\n",
    "  \n",
    "  After $n -1$ steps, $~$we eliminated all the matrix elements below the main diagonal, \n",
    "  $~$so we obtain an upper triangular matrix $\\mathbf{A}^{(n -1)}$. $~$We find the decomposition\n",
    "  \n",
    "  >$\n",
    "   \\mathbf{A}=\\mathbf{L}_1^{-1}\\mathbf{L}_1\\mathbf{A}^{(0)}=\\mathbf{L}_1^{-1}\\mathbf{A}^{(1)}\n",
    "     =\\mathbf{L}_1^{-1}\\mathbf{L}_2^{-1}\\mathbf{L}_2\\mathbf{A}^{(1)}=\\mathbf{L}_1^{-1}\\mathbf{L}_2^{-1}\\mathbf{A}^{(2)}\n",
    "     =\\cdots=\\mathbf{L}_1^{-1}\\cdots\\mathbf{L}_{n -1}^{-1}\\mathbf{A}^{(n -1)}\n",
    "  $\n",
    "  \n",
    "  Denote the upper triangular matrix $\\mathbf{A}^{(n -1)}$ by $\\mathbf{U}$, $~$and $\\mathbf{L}=\\mathbf{L}_1^{-1}\\cdots\\mathbf{L}_{n -1}^{-1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIqhXI3IAOtC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  Because the inverse of a lower triangular matrix $\\mathbf{L}_k$ is again a lower triangular matrix, \n",
    "  and the multiplication of two lower triangular matrices is again a lower triangular matrix, \n",
    "  it follows that $\\mathbf{L}$ is a lower triangular matrix. Moreover, it can be seen that\n",
    "  \n",
    "  >${\\scriptsize\n",
    "  \\mathbf{L}=\n",
    "     \\begin{pmatrix}\n",
    "         1      & 0      &           & \\cdots &          & 0      \\\\ \n",
    "         l_{2,1}& \\ddots & \\ddots    &        &          &        \\\\ \n",
    "                &        & 1         &        &          &        \\\\ \n",
    "        \\vdots  &        & l_{k+1,k} &        &          & \\vdots \\\\ \n",
    "                &        & \\vdots    &        & 1        & 0      \\\\ \n",
    "         l_{n,1}& \\cdots & l_{n,k}   & \\cdots & l_{n,n-1}& 1\n",
    "     \\end{pmatrix}}  \n",
    "  $\n",
    "  \n",
    "  We obtain $\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "  \n",
    "  **NOTE:** It is clear that in order for this algorithm to work, one needs to have $a_{k,k}^{(k-1)}$ at each step \n",
    "  (see the definition of $l_{i,k}$). If this assumption fails at some point, one needs to interchange $k$-th row \n",
    "  with another row below it before continuing. This is why an LU decomposition in general looks like \n",
    "  $\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4kZRVTFAOtD",
    "outputId": "abce374c-e4d8-4a76-b591-9ce1ed034571",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%run ./codes/ch08_code4.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3twS8ABLAOtI",
    "outputId": "8c0165dd-a273-475f-8636-8eb2e4e12d80",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "A = np.array([[7, 3, -1, 2], [3, 8, 1, -4], [-1, 1, 4, -1], [2, -4, -1, 6]], dtype='float64')\n",
    "P, L, U = lu(A)\n",
    "\n",
    "print('P ='); pprint.pprint(P)\n",
    "print('\\nL ='); pprint.pprint(L)\n",
    "print('\\nU ='); pprint.pprint(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Solving Linear Equations**\n",
    "\n",
    "  Given a system of linear equations in matrix form\n",
    "  \n",
    "  >$\\mathbf{A}\\mathbf{x}=\\mathbf{b}$\n",
    "  \n",
    "  Suppose we have already obtained the LUP decomposition of $\\mathbf{A}$ such that \n",
    "  $\\mathbf{P}\\mathbf{A}=\\mathbf{L}\\mathbf{U}$, so $\\mathbf{L}\\mathbf{U}\\mathbf{x}=\\mathbf{P}\\mathbf{b}$\n",
    "  \n",
    "  In this case the solution is done in two logical steps:\n",
    "\n",
    "  * First, $~$we solve the equation $\\mathbf{L}\\mathbf{y}=\\mathbf{P}\\mathbf{b}$ for $\\mathbf{y}$  \n",
    "  * Second, $~$we solve the equation $\\mathbf{U}\\mathbf{x}=\\mathbf{y}$ for $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1FSh4p_AOtK",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "  * Note that in both cases we are dealing with triangular matrices ($\\mathbf{L}$ and $\\mathbf{U}$), \n",
    "  which can be solved directly by forward and backward substitution without using the Gaussian elimination process \n",
    "  (however we do need this process or equivalent to compute the LU decomposition itself). \n",
    "  The cost of solving a system of linear equations is approximately $\\frac{2}{3}n^{3}$ floating-point operations.\n",
    "    \n",
    "  * The above procedure can be repeatedly applied to solve the equation multiple times for different $\\mathbf{b}$. \n",
    "  $~$In this case it is faster (and more convenient) to do an LU decomposition of the matrix $\\mathbf{A}$ \n",
    "  once and then solve the triangular matrices for the different $\\mathbf{b}$, rather than using Gaussian \n",
    "  elimination each time. \n",
    "  The matrices $\\mathbf{L}$ and $\\mathbf{U}$ could be thought to have *encoded* the Gaussian elimination process\n",
    "    \n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzVm9dt8AOtK",
    "outputId": "aa158a52-5f24-463a-d9a2-d781f8ad0a4c",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%run ./codes/ch08_code5.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwEOUWmqAOtM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Inverting a Matrix**\n",
    "\n",
    "  In matrix inversion, instead of vector $\\mathbf{b}$, $~$we have matrix $\\mathbf{I}_n$ so that we are trying to find a matrix $\\mathbf{X}$\n",
    "  \n",
    "  >$\\mathbf{L}\\mathbf{U}\\mathbf{X}=\\mathbf{I}_n$\n",
    "  \n",
    "  We can use the same algorithm presented earlier to solve for each column of matrix $\\mathbf{X}$\n",
    "  \n",
    "* **Computing the Determinant**\n",
    "\n",
    "  Given the LUP decomposition $\\mathbf{A}=\\mathbf{P}^{-1}\\mathbf{L}\\mathbf{U}$ of a square matrix $\\mathbf{A}$, \n",
    "  $~$the determinant of $\\mathbf{A}$ can be computed straightforwardly as\n",
    "  \n",
    "  >$\\displaystyle\\mathrm{det}\\,\\mathbf{A}=\\mathrm{det}\\,\\mathbf{P}^{-1}\\,\\mathrm{det}\\,\\mathbf{L}\\,\n",
    "  \\mathrm{det}\\,\\mathbf{U}=(-1)^s \\prod_{i=1}^n l_{ii}\\prod_{i=1}^n u_{ii}$\n",
    "   \n",
    "  where $s$ is the number of row exchanges in the permutation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fof98BqRAOtN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises 8.13\n",
    "\n",
    "* Find the LU factorization of the given matrix\n",
    "\n",
    "    $\\begin{pmatrix}\n",
    " 2 & -2\\\\ \n",
    " 1 & \\phantom{-}2\n",
    "\\end{pmatrix}, \\;\\; \\begin{pmatrix}\n",
    " -1 & 4 \\\\ \n",
    " \\phantom{-}2 & 2\n",
    "\\end{pmatrix}, \\;\\;\\begin{pmatrix}\n",
    " \\phantom{-}4 & -2 & 1\\\\ \n",
    " -4 & 1 & 2\\\\ \n",
    " 12 & 1 & 3\n",
    "\\end{pmatrix}$\n",
    "\n",
    "  $~$\n",
    "\n",
    "* Use the LU factorization to solve the given linear system of equations\n",
    "\n",
    "  $\\begin{pmatrix} 2 & -2 \\\\ 1 & \\phantom{-}2\\end{pmatrix}\n",
    "  \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \n",
    "  \\begin{pmatrix} \\phantom{-}1 \\\\-2 \\end{pmatrix}$\n",
    "\n",
    "  $\\begin{pmatrix} \n",
    "    \\phantom{-}4 & -2 & 1 \\\\ -4 & \\phantom{-}1 & 2\\\\12 & \\phantom{-}1 & 3\n",
    "  \\end{pmatrix}\n",
    "  \\begin{pmatrix} x_1 \\\\ x_2 \\\\x_3 \\end{pmatrix} = \n",
    "  \\begin{pmatrix} 7 \\\\ 7\\\\28 \\end{pmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dv8cYyUMAOtN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.14 Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwYHzOsjAOtO",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Cryptography**\n",
    "\n",
    "  Cryptography is the study of making *secret writings* or *codes*. $~$We will consider a system of encoding and decoding\n",
    "  messages that requires both the sender and the receiver to know:\n",
    "  \n",
    "  * a specified rule of correspondence between a set of symbols and a set of integers; and \n",
    "  * a specified *nonsingular* matrix $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-cAewswAOtP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  **Example:** $\\text{ }$ A correspondence between the twenty-seven integers and the letters of the alphabet and a blank space is given by\n",
    "  \n",
    "  >$\\scriptsize\n",
    "   \\begin{align*}\n",
    "     &\\begin{matrix}\n",
    "       0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 &10 &11 &12 &13 &14 &15 &16 &17 &18 &19 &20 \\\\ \n",
    "       \\text{space} & j & k & l & n & m & s & t & u & w & x & g & h & i & o & p & q & r & v & y & z    \n",
    "      \\end{matrix} \\\\ \n",
    "   & \\\\\n",
    "   &\\;\\text{ }  \n",
    "   \\begin{matrix}\n",
    "       21 &22 &23 &24 &25 &26 \\\\ \n",
    "       a & b & c & d & e & f   \n",
    "     \\end{matrix} \n",
    "   \\end{align*}$\n",
    "  \n",
    "  The numerical equivalent of the message **DR JOHN IS A DOUBLE SPY** is \n",
    "  \n",
    "  > $\\scriptsize\\begin{matrix}\n",
    "        24 & 17 & 0 & 1 & 14 & 12 & 4 & 0 & 13 & 6 & 0 & 21 & 0 & 24 & 14 & 8 & 22 & 3 & 25 & 0 & 6 & 15 & 19\n",
    "      \\end{matrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  The sender will **encode** the message by means of the nonsingular matrix $\\mathbf{A}$ and the receiver will **decode**\n",
    "  the encoded message by means of the matrix $\\mathbf{A}^{-1}$. $~$We choose to write the numerical message as the $3 \\times 8$ matrix\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{M}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "      24 & 17 & 0 & 1 & 14 & 12 & 4 & 0 \\\\ \n",
    "      13 & 6 & 0 & 21 & 0 & 24 & 14 & 8 \\\\ \n",
    "      22 & 3 & 25 & 0 & 6 & 15 & 19 & 0 \n",
    "    \\end{array}\\right)  \n",
    "  $\n",
    "  \n",
    "  Note that the last entry $m_{38}$ has been simply padded with a space (the number $0$). $~$A $3 \\times 8$ matrix allows us\n",
    "  to encode the message by means of a $3 \\times 3$ matrix. The encoding matrix $\\mathbf{A}$ is constructed, so that\n",
    "  \n",
    "  * $\\mathbf{A}$ is nonsingular\n",
    "  * $\\mathbf{A}$ has only integer entries, and\n",
    "  * $\\mathbf{A}^{-1}$ has only integer entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  To accomplish the last criterion, $~$we need only select the integer entries of $\\mathbf{A}$ in such a manner that \n",
    "  $\\mathrm{det}\\,\\mathbf{A}=\\pm 1$. $~$We choose\n",
    "      \n",
    "  >$\n",
    "  \\mathbf{A}=\n",
    "    \\left(\\begin{array}{rrr}\n",
    "        -1 & 0 &-1 \\\\\n",
    "        2 & 3 & 4 \\\\\n",
    "        2 & 4 & 5\n",
    "     \\end{array}\\right) \n",
    "  $\n",
    "  \n",
    "  and\n",
    "  \n",
    "  >$\n",
    "  \\mathbf{A}^{-1}=\n",
    "    \\left(\\begin{array}{rrr}\n",
    "        1 & 4 &-3 \\\\\n",
    "        2 & 3 &-2 \\\\\n",
    "       -2 &-4 & 3\n",
    "     \\end{array}\\right)  \n",
    "  $  \n",
    "      \n",
    "  You should verify that $\\mathrm{det}\\,\\mathbf{A}=-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7Yhk4SUAOtQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " The original message is encoded as following:\n",
    "      \n",
    "  >${\\scriptsize\\mathbf{B}=\\mathbf{A}\\mathbf{M}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "     -46 & -20 & -25 & -1 & -20 & -27 & -23 & 0 \\\\ \n",
    "     175 &  64 & 100 & 65 & 52 & 156 & 126 & 24 \\\\ \n",
    "     210 &  73 & 125 & 86 & 58 & 195 & 159 & 32 \n",
    "    \\end{array}\\right)}   \n",
    "  $\n",
    "  \n",
    "  It may be desirable to send the encoded message as letters of the alphabet rather than as numbers. \n",
    "  Thus we rewrite $\\mathbf{B}$ as $\\mathbf{B}'$ using integers modulo 27:\n",
    "  \n",
    "  >${\\scriptsize\\mathbf{B'}=\n",
    "    \\left(\\begin{array}{rrrrrrrr}\n",
    "     8 & 7 & 2 & 26 & 7 & 0 & 4 & 0 \\\\ \n",
    "     13 &  10 & 19 & 11 & 25 & 21 & 18 & 24 \\\\ \n",
    "     21 &  19 & 17 & 5 & 4 & 6 & 24 & 5 \n",
    "    \\end{array}\\right)}   \n",
    "  $ \n",
    "  \n",
    "  The encoded message to be sent in letters is\n",
    "  \n",
    "  > **UTKFT N IXYGEAVDAYRMNSDM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#-- Data for Encoding and Decoding------------------------------------\n",
    "\n",
    "cp = { 0:' ',  1:'j',  2:'k',  3:'l',  4:'n',  5:'m',  6:'s',  7:'t',    \n",
    "       8:'u',  9:'w', 10:'x', 11:'g', 12:'h', 13:'i', 14:'o', 15:'p',  \n",
    "      16:'q', 17:'r', 18:'v', 19:'y', 20:'z', 21:'a', 22:'b', 23:'c', \n",
    "      24:'d', 25:'e', 26:'f' }\n",
    "\n",
    "A = np.array([[-1, 0, -1], [2, 3, 4], [2, 4, 5]])\n",
    "\n",
    "inv_cp =  {v: k for k, v in cp.items()}\n",
    "inv_A = np.rint(np.linalg.inv(A)).astype('int32')\n",
    "\n",
    "#----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_numeric(message):   \n",
    "    return np.array([inv_cp[m] for m in message])\n",
    "\n",
    "def convert_to_letter(numeric_message):\n",
    "    return ''.join([cp[m] for m in numeric_message])\n",
    "\n",
    "def encoding_message(message):  \n",
    "    \n",
    "    numeric_message = convert_to_numeric(message)\n",
    "    \n",
    "    n_app = (3 -len(numeric_message) % 3) % 3\n",
    "    M = np.append(numeric_message, [0]*n_app).reshape(3, -1)\n",
    "    B = (A @ M) % 27\n",
    "\n",
    "    numeric_message_encoded = B.flatten()\n",
    "    \n",
    "    return convert_to_letter(numeric_message_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvYj98djAOtT",
    "outputId": "1e7b9346-d068-4e89-99dc-ef956a53640d",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "message = 'dr john is a double spy'\n",
    "message_encoded = encoding_message(message)\n",
    "\n",
    "print('Message =', message.upper())\n",
    "print('Encoded message =', message_encoded.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fY5wsbQgAOtV",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You should try to imagine the difficulty of decoding the encoded message without prior knowledge. \n",
    "$~$Using the original correspondence and $\\mathbf{A}$, $~$the decoding is the straightforward computation\n",
    "\n",
    "> $\\mathbf{M}=\\mathbf{A}^{-1}\\mathbf{B}'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcP5Y9YRAOtV",
    "outputId": "db2ca33b-0c02-4e8a-c472-64d137a4b280",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def decoding_message(message_encoded):\n",
    "    \n",
    "    B_ = convert_to_numeric(message_encoded).reshape(3, -1)\n",
    "    M_ = (inv_A @ B_) % 27\n",
    "    \n",
    "    numeric_message_decoded = M_.flatten()\n",
    "    \n",
    "    return convert_to_letter(numeric_message_decoded)\n",
    "\n",
    "message_decoded = decoding_message(message_encoded)\n",
    "\n",
    "print('Decoding message =', message_decoded.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FtC5LRTAOtX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **An Error-Correcting Code**\n",
    "\n",
    "  We are going to examine briefly the concept of digital communication, say, $~$communication between \n",
    "  a satellite and a computer.\n",
    "  $~$As a result, $~$we will deal only with matrices whose entries are binary digits, namely $0$s and $1$s. \n",
    "  When addng and multipying such matrices,\n",
    "  $~$we will use arithmetic modulo 2. This arithmetic is defined by the addition and multiplication tables\n",
    "\n",
    "\n",
    ">| + | 0 | 1 |\n",
    "|---|---|---| \n",
    "| **0** | 0 | 1 |\n",
    "| **1** | 1 |<font color='red'> 0 </font>|\n",
    "\n",
    ">| x | 0 | 1 |\n",
    "|---|---|---| \n",
    "| **0** | 0 | 0 |\n",
    "| **1** | 0 | 1 |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* In digital communication the messages or words are binary $n$-tuples. $~$An $n$-bit word is also said \n",
    "  to be a binary string of length $n$. By **encoding** a message, $~$we mean a process whereby we transform\n",
    "  a word $\\mathbf{W}$ of length $n$ into another word $\\mathbf{C}$ of length $n +m$ by augmenting $\\mathbf{W}$\n",
    "  with $m$ additional bits, $~$called **parity check bits**. $~$An encoding/decoding scheme is called a **code**\n",
    "  \n",
    "  The **Hamming (7, 4) code** is an encoding/decoding scheme that can detect the presence of a single error\n",
    "  in a received message and can tell which bit must be corrected. In $(7, 4)$ code the encoding process\n",
    "  consists of transforming a 4-bit word \n",
    "  \n",
    "  >$\\mathbf{W}=\\begin{bmatrix} w_1 & w_2 & w_3 & w_4 \\end{bmatrix}$\n",
    "  \n",
    "  into a 7-bit code word\n",
    "  \n",
    "  >$\\mathbf{C}=\\begin{bmatrix} \\color{green}{c_1} & \\color{green}{c_2} & w_1 & \\color{green}{c_3} & w_2 & w_3 & w_4 \\end{bmatrix}$\n",
    "  \n",
    "  where $c_1$, $c_2$, and $c_3$ denote the parity check bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " and are defined in terms of the information bits $w_1$, $w_2$, $w_3$, and $w_4$\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        c_1 &= w_1 +w_2 +w_4\\\\ \n",
    "        c_2 &= w_1 +w_3 +w_4\\\\ \n",
    "        c_3 &= w_2 +w_3 +w_4\n",
    "    \\end{align*} \\;\\;\\;\\;\\;\\text{(C1)} \n",
    "  $ \n",
    "  \n",
    "  We first observe that in modulo 2 arithmatic there are no negative numbers; $~$the additive inverse\n",
    "  is $1$, not $-1$. $~$With this in mind, $~$we can write the system $\\text{(C1)}$ in the equivalent form\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        c_3 &+ w_2 +w_3 +w_4 = 0\\\\\n",
    "        c_2 &+ w_1 +w_3 +w_4 = 0\\\\        \n",
    "        c_1 &+ w_1 +w_2 +w_4 = 0 \n",
    "    \\end{align*} \\;\\;\\;\\;\\; \\text{(C2)}   \n",
    "  $ \n",
    "  \n",
    "  These are called **parity check equations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " As a matrix product, $~\\text{(C2)}$ can be written\n",
    "  \n",
    "  >$\\mathbf{H}\\mathbf{C}^T=\\mathbf{0}$\n",
    "  \n",
    "  where \n",
    "  \n",
    "  >$\\mathbf{H}=\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 1 & 1 & 1 & 1\\\\ \n",
    "        0 & 1 & 1 & 0 & 0 & 1 & 1\\\\\n",
    "        1 & 0 & 1 & 0 & 1 & 0 & 1\n",
    "    \\end{pmatrix}$\n",
    "  \n",
    "  is called the **parity check matrix**. $~$A closer inspection of $\\mathbf{H}$ shows \n",
    "  a surprising fact: The columns of $\\mathbf{H}$, left to right, are \n",
    "  the numbers $1$ through $7$ written in binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  Let $\\mathbf{R}$ be a $1 \\times 7$ matrix representing the received message. The product\n",
    "  \n",
    "  >$\\mathbf{S}=\\mathbf{H}\\mathbf{R}^T$\n",
    "  \n",
    "  is called the **syndome** of $\\mathbf{R}$. $~$If $\\mathbf{S}=\\mathbf{0}$, $~$it is assumed that\n",
    "  the transmission is correct and that $\\mathbf{R}$ is the same as the original encoded \n",
    "  message $\\mathbf{C}$. $~$The decoding of the message is accomplished by simply dropping the \n",
    "  three check bits in $\\mathbf{R}$\n",
    "  \n",
    "  Let \n",
    "  \n",
    "  >$\\mathbf{E}=\\begin{bmatrix} e_1 & e_2 & e_3 & e_4 & e_5 & e_6 & e_7 \\end{bmatrix}$\n",
    "  \n",
    "  be a *single-error noise* word added to $\\mathbf{C}$ during its transmission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jTthgvcAOtY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  If noise changes the $i$-th bit, $~e_i=1$. $~$The received message is then \n",
    "  $\\mathbf{R}=\\mathbf{C}+\\mathbf{E}$. $~$We see that\n",
    "  \n",
    "  >$\\begin{align*}\n",
    "     \\mathbf{S}&=\\mathbf{H}\\mathbf{R}^T\n",
    "            =\\mathbf{H}(\\mathbf{C}^T +\\mathbf{E}^T)=\\mathbf{H}\\mathbf{E}^T\\\\\n",
    "        &= e_1 \\begin{pmatrix} 0\\\\ 0\\\\ 1\\end{pmatrix}\n",
    "          +e_2 \\begin{pmatrix} 0\\\\ 1\\\\ 0\\end{pmatrix}\n",
    "          +e_3 \\begin{pmatrix} 0\\\\ 1\\\\ 1\\end{pmatrix}\n",
    "          +e_4 \\begin{pmatrix} 1\\\\ 0\\\\ 0\\end{pmatrix}\n",
    "          +e_5 \\begin{pmatrix} 1\\\\ 0\\\\ 1\\end{pmatrix} \n",
    "          +e_6 \\begin{pmatrix} 1\\\\ 1\\\\ 0\\end{pmatrix}\n",
    "          +e_7 \\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix}           \n",
    "    \\end{align*}    \n",
    "   $\n",
    "   \n",
    "   Hence, if $\\mathbf{S}\\neq\\mathbf{0}$, $~$then $\\mathbf{S}$ must be one of \n",
    "   the columns of $\\mathbf{H}$. $~$If $\\mathbf{R}$ contains a single error, $~$we see that\n",
    "   the syndrome itself indicates which bit is in error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Method of Least Squares**\n",
    "\n",
    "  ><img src=\"figures/ch08_figure06.png\" width=\"340\">\n",
    "\n",
    "  When performing experiments we often tabulate data in the form of ordered pairs $(x_1, y_1)$,\n",
    "  $(x_2, y_2)$, $\\cdots$, $(x_n, y_n)$, with each $x_i$ distinct. Given the data, it is then often\n",
    "  desirable to predict $y$ from $x$ by finding a mathematical model, that is, \n",
    "  a function $f(x)$ that approximates or fits the data\n",
    "  \n",
    "  We shall confine our attention to the problem of finding a linear polynomial\n",
    "  $f(x)=ax +b$ that best fits the data $(x_i, y_i)$, $i=1,\\cdots, n$. The procedure\n",
    "  for finding this linear function is known as **the method of least squares**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  One way to determine how well the linear function $f(x)=ax +b~$ fits the data is to\n",
    "  measure the vertical distances between the data points $y_i$ and the graphs $f(x_i)$\n",
    "  \n",
    "  >$e_i=|y_i -f(x_i)|$, $\\;i=1,\\cdots, n$\n",
    "  \n",
    "  An actual approach is to find a linear function $f$ so that\n",
    "  the sum of the *squares* of all the $e_i$ values is a minimum\n",
    "  \n",
    "  >$\\displaystyle\\min_{a, \\,b} E=\\min_{a, \\,b} \\sum_{i=1}^n \\left[y_i -ax_i -b\\right]^2$\n",
    "  \n",
    "  Then to find the minimum value of $E$, $~$we set the first partial derivatives with respect to\n",
    "  $a$ and $b$ to zero:\n",
    "  \n",
    "  >$\\displaystyle \\frac{\\partial E}{\\partial a}=0 \\;\\text{ and }\\; \\frac{\\partial E}{\\partial b}=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  The last two conditions yield, in turn,\n",
    "  \n",
    "  >$\n",
    "    \\begin{align*}\n",
    "        -2 \\sum_{i=1}^n x_i [y_i -a x_i -b] &= 0\\\\ \n",
    "        -2 \\sum_{i=1}^n [y_i -a x_i -b] &= 0\n",
    "    \\end{align*}  \n",
    "  $\n",
    "\n",
    "  Expanding the sums and rearranging, $~$we find the above system is the same as\n",
    "  \n",
    "  >$\n",
    "    \\begin{pmatrix}\n",
    "     \\displaystyle\\sum_{i=1}^n x_i^2 & \\displaystyle\\sum_{i=1}^n x_i\\\\ \n",
    "     \\displaystyle\\sum_{i=1}^n x_i   & n\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix}\n",
    "      a \\\\ b\n",
    "    \\end{pmatrix}=\n",
    "    \\begin{pmatrix}\n",
    "     \\displaystyle \\sum_{i=1}^n x_i y_i\\\\ \\displaystyle \\sum_{i=1}^n y_i \\;\\;\\;\n",
    "    \\end{pmatrix}  \n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8RTTNBfAOtZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "  and, in terms of matrices, is  equivalent to \n",
    "  \n",
    "  >$\\mathbf{A}^T\\mathbf{A}\\mathbf{x}=\\mathbf{A}^T\\mathbf{b}$\n",
    "  \n",
    "  where\n",
    "  \n",
    "  >$\n",
    "    \\mathbf{A}=\n",
    "    \\begin{pmatrix}\n",
    "     x_1 & 1\\\\ \n",
    "     x_2 & 1\\\\ \n",
    "     \\vdots & \\vdots\\\\ \n",
    "     x_n & 1 \n",
    "    \\end{pmatrix},\n",
    "    \\;\\mathbf{b}=\n",
    "    \\begin{pmatrix}\n",
    "     y_1\\\\\n",
    "     y_2\\\\ \n",
    "     \\vdots\\\\ \n",
    "     y_n\n",
    "    \\end{pmatrix},\n",
    "    \\;\\mathbf{x}=\n",
    "    \\begin{pmatrix}\n",
    "     a \\\\ b\n",
    "    \\end{pmatrix}\n",
    "    \\;\\;\\text{(LS)}\n",
    "  $ \n",
    "  \n",
    "  Unless the data points all lie on the same vertical line, the matrix $\\mathbf{A}^T\\mathbf{A}$\n",
    "  is nonsingular. Thus $\\text{(LS)}$ has the unique solution\n",
    "  \n",
    "  >$\n",
    "    \\mathbf{x} =\\left(\\mathbf{A}^T \\mathbf{A} \\right)^T \\mathbf{A}^T \\mathbf{b}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkM51c3nAOta",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example** $\\text{ }$ Nonlinear Least Squares: $\\text{ } f(x) = 2.5e^{-1.3x}$\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SeoulTechPSE/EngMath/blob/master/codes/ch08_code6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdIPnmm_AOtb",
    "outputId": "f3179fd1-d8b1-42c3-b4db-e999a0ad665b",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%run ./codes/ch08_code6.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Discrete Compartmental Models**\n",
    "\n",
    "  Strontium 90 is deposited into pastureland by rainfall. To study how this material is \n",
    "  cycled through the ecosystem, $~$we divide the system into the compartments shown in the following\n",
    "\n",
    "  ><img src=\"figures/ch08_figure07.png\" width=\"600\">\n",
    "  \n",
    "  Suppose that $\\Delta t=1$ month and the transfer coefficients (which have been estimated\n",
    "  experimentally) shown in the figure are measured in fraction/month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pw0VG2fDAOtd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Suppose that rainfall has\n",
    "  deposited the strotium 90 into the compartments so that\n",
    "  \n",
    "  >$\\mathbf{x}_0=\n",
    "   \\begin{pmatrix}\n",
    "    20 & \n",
    "    60 & \n",
    "    15 & \n",
    "    20\n",
    "   \\end{pmatrix}^T$\n",
    "   \n",
    "  Units might be grams per hectare. Compute the states of the ecosystem over the next 12 months\n",
    "  \n",
    "  *Solution* $~$From the data in figure, $~$we see that transfer matrix $\\mathbf{T}$ is\n",
    "  \n",
    "  >$\\scriptsize\n",
    "    \\mathbf{T}=\n",
    "    \\begin{pmatrix}\n",
    "     0.85 & 0.01 & 0   & 0 \\\\ \n",
    "     0.05 & 0.98 & 0.2 & 0 \\\\ \n",
    "     0.1  & 0    & 0.8 & 0 \\\\ \n",
    "     0    & 0.01 & 0   & 1\n",
    "    \\end{pmatrix}  \n",
    "  $\n",
    "  \n",
    "  We must compute $\\mathbf{x}_1$, $\\mathbf{x}_2$, $\\cdots$, $\\mathbf{x}_{12}$ by using\n",
    "  the recursion formula $~\\mathbf{x}_{n+1}=\\mathbf{T}\\mathbf{x}_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB5SOiudAOtd",
    "outputId": "e9217c98-072a-40a1-d6f5-ea776a276c20",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "T = np.array([[0.85, 0.01, 0.00, 0.00], \n",
    "              [0.05, 0.98, 0.20, 0.00],\n",
    "              [0.10, 0.00, 0.80, 0.00], \n",
    "              [0.00, 0.01, 0.00, 1.00]])\n",
    "x = np.array([20, 60, 15, 20]).T\n",
    "\n",
    "print('-' * 47)\n",
    "print('Month     Grasses   Soil      Dead_OM   Streams')\n",
    "print('-' * 47)\n",
    "for month in range(13):   \n",
    "    print(f'{month:5d} {x[0]:9.2f} {x[1]:9.2f} {x[2]:9.2f} {x[3]:9.2f}')  \n",
    "    x = T @ x  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "include_colab_link": true,
   "name": "ch08.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
